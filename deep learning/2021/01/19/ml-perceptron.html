<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Pengenalan Kepada Multilayer Perceptron | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Pengenalan Kepada Multilayer Perceptron" />
<meta name="author" content="Megat Norulazmi" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Perbincangan berkenaan kelemahan perceptron dan bagaimana multilayer perceptron memperbaiki kelemahan tersebut dengan bantuan backpropagation" />
<meta property="og:description" content="Perbincangan berkenaan kelemahan perceptron dan bagaimana multilayer perceptron memperbaiki kelemahan tersebut dengan bantuan backpropagation" />
<link rel="canonical" href="https://megatazm.github.io/MyDLBlog/deep%20learning/2021/01/19/ml-perceptron.html" />
<meta property="og:url" content="https://megatazm.github.io/MyDLBlog/deep%20learning/2021/01/19/ml-perceptron.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://megatazm.github.io/MyDLBlog/images/" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-19T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"Perbincangan berkenaan kelemahan perceptron dan bagaimana multilayer perceptron memperbaiki kelemahan tersebut dengan bantuan backpropagation","url":"https://megatazm.github.io/MyDLBlog/deep%20learning/2021/01/19/ml-perceptron.html","@type":"BlogPosting","headline":"Pengenalan Kepada Multilayer Perceptron","dateModified":"2021-01-19T00:00:00-06:00","datePublished":"2021-01-19T00:00:00-06:00","author":{"@type":"Person","name":"Megat Norulazmi"},"image":"https://megatazm.github.io/MyDLBlog/images/","mainEntityOfPage":{"@type":"WebPage","@id":"https://megatazm.github.io/MyDLBlog/deep%20learning/2021/01/19/ml-perceptron.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/MyDLBlog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://megatazm.github.io/MyDLBlog/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/MyDLBlog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/MyDLBlog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/MyDLBlog/about/">About Me</a><a class="page-link" href="/MyDLBlog/search/">Search</a><a class="page-link" href="/MyDLBlog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Pengenalan Kepada Multilayer Perceptron</h1><p class="page-description">Perbincangan berkenaan kelemahan perceptron dan bagaimana multilayer perceptron memperbaiki kelemahan tersebut dengan bantuan backpropagation</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-01-19T00:00:00-06:00" itemprop="datePublished">
        Jan 19, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Megat Norulazmi</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/MyDLBlog/categories/#deep learning">deep learning</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-01-19-ml-perceptron.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assalamualaikum dan selamat berjumpa kembali.</p>
<p>Pada <a href="https://megatazm.github.io/MyDLBlog/deep%20learning/2021/01/11/perceptron-ml-sklearn.html">artikel yang lepas</a>, kita telah menggunakan perceptron sebagai contoh algoritma di dalam proses machine learning. Seperti yang anda ketahui, algoritma perceptron ini telah di cipta hampir 60 tahun yang lampau. Ia tidak lah cukup berkuasa untuk menyelesai keperluan masa kini yang kompleks dan mencabar. Malahan, kelemahan perceptron yang di temui oleh Marvin Minsky and Seymour Papert pada tahun 1969 telah menyebabkan algoritma berdasarkan pada konsep neural network ini terkubur hampir dua dekad lamanya.</p>
<p>Kenapa? &lt;(^,^)&gt;</p>
<p>Jika anda membaca artikel saya sebelum ini, ada dinyatakan bahawa perceptron hanya mampu melakukan klasifikasi binari yang datanya adalah <strong><em>lineary separable</em></strong>.</p>
<p>Masih ingat? (;¬_¬)</p>
<p>Kekangan yang ada pada perceptron ini digambarkan seperti di bawah melalui apa yang dikenali sebagai masalah XOR. Gambarajah di bawah juga menunjukkan perbandingan antara 2 fungsi logik OR dan XOR.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br />
<br />
<figure>
  
    <img class="docimage" src="/MyDLBlog/images/copied_from_nb/fastcore_imgs/xor-problem.png" alt="xor problem" style="max-width: 100%px" />
    
    
</figure>

<br />
<br /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Di bawah adalah <strong>Truth Table</strong> menunjukkan hubungan input &amp; output yang dihasilkan oleh fungsi logik OR dan XOR (Merujuk pada gambarajah di atas, simbol dot merah = 0 manakala simbol plus biru = 1).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br />
<br />
<figure>
  
    <img class="docimage" src="/MyDLBlog/images/copied_from_nb/fastcore_imgs/xor-or-truthtable.png" alt="xor-or-truthtable" style="max-width: 100%px" />
    
    
</figure>

<br />
<br /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sekiranya kita train perceptron untuk memperolehi model yang berkebolehan seperti fungsi <strong>OR</strong> dan <strong>XOR</strong> ini, kita dapat melihat pada gambarajah di plot kiri (fungsi OR), bahawa perceptron boleh melakukannya melalui satu garisan linear. Namun, pada plot di kanan (fungsi XOR), perceptron tidak mampu melakukanya kerana fungsi XOR adalah dikatakan "<strong><em>linearly non-separable</em></strong>". Satu-satunya cara untuk memisahkan kedua-dua kelas (biru dan merah) ini adalah dengan menggunakan garisan sempadan bukan linear. Ini jelas menunjukkan bahawa perceptron boleh mempelajari fungsi OR tetapi tidak dapat mempelajari fungsi XOR.</p>
<p>Sungguh mengecewakan! ╭╮(︶︿︶)╭╮</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Secara teorinya kelemahan perceptron itu dapat diselesaikan dengan menambah satu lagi lapisan neuron diatasnya. Ini menghasilkan apa yang disebut sebagai <strong>Multilayer Perceptron</strong> (<strong>MLP</strong>). Gambarajah di bawah menunjukkan bagaimana MLP dapat menyelesaikan masalah XOR. Melalui proses training, gambarajah di bawah menunjukkan nilai weight pada semua sambungan (anak panah) NN yang berwarna hitam adalah 1, manakala yang berwarna merah di tanda dengan nilai seperti di gambarajah. Jika kita menghitung output MLP itu dengan input (0, 0) atau (1, 1), hasil output=0. Manakala jika dengan input (0, 1) atau (1, 0) ia menghasilkan output=1.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br />
<br />
<figure>
  
    <img class="docimage" src="/MyDLBlog/images/copied_from_nb/fastcore_imgs/mlp-solved-xor.png" alt="mlp-solved-xor" style="max-width: 100%px" />
    
    
</figure>

<br />
<br /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Boleh nampak tak? Ok lah saya tunjukkan pengiraannya dengan terperinchi. Sebelum itu, sila rujuk pada penerangan berkenaan perceptron di <a href="https://megatazm.github.io/MyDLBlog/deep%20learning/2020/12/29/basic-dl.html">artikel saya yang sebelum ini</a>. Di bawah adalah rumus yang digunakan untuk mengira output yang keluar di lapisan neuron kedua (hidden layer).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br /></p>
<p><img src="https://latex.codecogs.com/png.download?%5Clarge%20%5Cbegin%7Bmatrix%7D%20%5C%5C%20f_%7Bs_%7Bi%7D%7D%5Cleft%20%28%20z%20%5Cright%20%29%3DWX%20+%20B%20%3D%20%5Cbegin%7Bbmatrix%7D%20w_%7B1%2C1%7D%20%26%20w_%7B1%2C2%7D%20%5C%5C%20w_%7B2%2C1%7D%20%26%20w_%7B2%2C2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D%20x_%7B1%7D%20%5C%5C%20x_%7B2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D%20+%20%5Cbegin%7Bbmatrix%7D%20b_%7B1%7D%20%5C%5C%20b_%7B2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D%20%5C%5C%20%5C%5C%20%3D%5Cbegin%7Bbmatrix%7D%20w_%7B1%2C1%7D%5Ctimes%20x_%7B1%7D%20+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D%20%5C%5C%20w_%7B2%2C1%7D%5Ctimes%20x_%7B1%7D%20+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D+%5Cbegin%7Bbmatrix%7D%20b_%7B1%7D%20%5C%5C%20b_%7B2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D%20%5Cend%7Bmatrix%7D" alt="equation" />
<br /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Mari kita menghitung nilai output neuron 1 dan neuron 2 di hidden layer terlebih dahulu.</p>
<ul>
<li><p>Nilai trained weights:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20w_%7B1%2C1%7D%3D1%2Cw_%7B1%2C2%7D%3D1%2Cw_%7B2%2C1%7D%3D1%2Cw_%7B2%2C2%7D%3D1" alt="equation" /></p>
</li>
<li><p>Nilai trained biases weight:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20b_%7B1%7D%3D-1.5%2Cb_%7B2%7D%3D-0.5" alt="equation" /></p>
</li>
<li><p>Ketika input:</p>
</li>
</ul>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D0%2Cx_%7B2%7D%3D0" alt="equation" /></p>
<ul>
<li><p>Oleh itu output neuron 1 &amp; 2:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20z_%7B1%7D%3Dw_%7B1%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B1%7D%3D%281%29%5Ctimes%280%29+%281%29%5Ctimes%280%29+%28-1.5%29%20%5C%5C%20z_%7B2%7D%3Dw_%7B2%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B2%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B2%7D%3D%281%29%5Ctimes%280%29+%281%29%5Ctimes%280%29+%28-0.5%29%20%5C%5C%20%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B1%7D%7D%28z_%7B1%7D%29%3Df_%7Bs_%7B1%7D%7D%28-1.5%29%3D0%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B2%7D%7D%28z_%7B2%7D%29%3Df_%7Bs_%7B2%7D%7D%28-0.5%29%3D0%5C%5C%20%5Cend%7Bmatrix%7D" alt="equation" /></p>
</li>
</ul>
<ul>
<li><p>Ketika input:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D1%2Cx_%7B2%7D%3D1" alt="equation" /></p>
</li>
<li><p>Oleh itu output neuron 1 &amp; 2:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20z_%7B1%7D%3Dw_%7B1%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B1%7D%3D%281%29%5Ctimes%281%29+%281%29%5Ctimes%281%29+%28-1.5%29%20%5C%5C%20z_%7B2%7D%3Dw_%7B2%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B2%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B2%7D%3D%281%29%5Ctimes%281%29+%281%29%5Ctimes%281%29+%28-0.5%29%20%5C%5C%20%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B1%7D%7D%28z_%7B1%7D%29%3Df_%7Bs_%7B1%7D%7D%280.5%29%3D1%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B2%7D%7D%28z_%7B2%7D%29%3Df_%7Bs_%7B2%7D%7D%281.5%29%3D1%5C%5C%20%5Cend%7Bmatrix%7D" alt="equation" /></p>
</li>
<li><p>Ketika input:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D1%2Cx_%7B2%7D%3D0" alt="equation" /></p>
</li>
<li><p>Oleh itu output neuron 1 &amp; 2:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20z_%7B1%7D%3Dw_%7B1%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B1%7D%3D%281%29%5Ctimes%281%29+%281%29%5Ctimes%280%29+%28-1.5%29%20%5C%5C%20z_%7B2%7D%3Dw_%7B2%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B2%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B2%7D%3D%281%29%5Ctimes%281%29+%281%29%5Ctimes%280%29+%28-0.5%29%20%5C%5C%20%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B1%7D%7D%28z_%7B1%7D%29%3Df_%7Bs_%7B1%7D%7D%28-0.5%29%3D0%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B2%7D%7D%28z_%7B2%7D%29%3Df_%7Bs_%7B2%7D%7D%280.5%29%3D1%5C%5C%20%5Cend%7Bmatrix%7D" alt="equation" /></p>
</li>
<li><p>Ketika input:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D0%2Cx_%7B2%7D%3D1" alt="equation" /></p>
</li>
<li><p>Oleh itu output neuron 1 &amp; 2:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20z_%7B1%7D%3Dw_%7B1%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B1%7D%3D%281%29%5Ctimes%280%29+%281%29%5Ctimes%281%29+%28-1.5%29%20%5C%5C%20z_%7B2%7D%3Dw_%7B2%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B2%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B2%7D%3D%281%29%5Ctimes%280%29+%281%29%5Ctimes%281%29+%28-0.5%29%20%5C%5C%20%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B1%7D%7D%28z_%7B1%7D%29%3Df_%7Bs_%7B1%7D%7D%28-0.5%29%3D0%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B2%7D%7D%28z_%7B2%7D%29%3Df_%7Bs_%7B2%7D%7D%280.5%29%3D1%5C%5C%20%5Cend%7Bmatrix%7D" alt="equation" /></p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Di bawah adalah rumus yang digunakan untuk mengira output final yang keluar di lapisan neuron ketiga (output layer).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20f_%7Bs_%7Boutput%7D%7D%28z%29%3D%5Cbegin%7Bbmatrix%7D%20w_%7B1%2C1%7D%20%26%20w_%7B1%2C2%7D%20%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D%20x_%7B1%7D%5C%5C%20x_%7B2%7D%5C%5C%20%5Cend%7Bbmatrix%7D+%5Cbegin%7Bbmatrix%7D%20b_%7B1%7D%20%5Cend%7Bbmatrix%7D%20%5C%5C%20%5C%5C%20x_%7B1%7D%3D%20f_%7Bs_%7B1%7D%28z%29%7D%5C%5C%20x_%7B2%7D%3D%20f_%7Bs_%7B2%7D%28z%29%7D%5C%5C%20%5Cend%7Bmatrix%7D" alt="equation" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Untuk menghitung nilai output neuron di output layer, inputnya adalah nilai output yang dihasilkan oleh 2 neuron dari hidden layer sebelum ini.</p>
<ul>
<li><p>Nilai trained weights:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20w_%7B1%2C1%7D%3D-1%2C%20w_%7B2%2C1%7D%3D1" alt="equation" /></p>
</li>
<li><p>Nilai trained biases weight:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20b_%7B1%7D%3D-0.5" alt="equation" /></p>
</li>
<li><p>ketika input:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D0%2Cx_%7B2%7D%3D0" alt="equation" /></p>
</li>
<li><p>Oleh itu nilai output:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20%5C%5C%20z%3Dw_%7B1%2C1%7D%5Ctimes%20x_%7B1%7D+w_%7B2%2C1%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%20%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z%3D%28-1%29%5Ctimes%20%280%29+%281%29%5Ctimes%20%280%29+%28-0.5%29%20%5C%5C%20%5C%5C%5Ctherefore%20%5C%3B%20f_%7Bs_%7Boutput%7D%7D%28-0.5%29%3D0%20%5Cend%7Bmatrix%7D" alt="equation" /></p>
</li>
<li><p>Ketika input:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D1%2Cx_%7B2%7D%3D1" alt="equation" /></p>
</li>
<li><p>Oleh itu nilai output:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20%5C%5C%20z%3Dw_%7B1%2C1%7D%5Ctimes%20x_%7B1%7D+w_%7B2%2C1%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%20%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z%3D%28-1%29%5Ctimes%20%281%29+%281%29%5Ctimes%20%281%29+%28-0.5%29%20%5C%5C%20%5C%5C%5Ctherefore%20%5C%3B%20f_%7Bs_%7Boutput%7D%7D%28-0.5%29%3D0%20%5Cend%7Bmatrix%7D" alt="equation" /></p>
</li>
<li><p>Ketika input:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D0%2Cx_%7B2%7D%3D1" alt="equation" /></p>
</li>
<li><p>Oleh itu nilai output:</p>
<p><img src="https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20%5C%5C%20z%3Dw_%7B1%2C1%7D%5Ctimes%20x_%7B1%7D+w_%7B2%2C1%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%20%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z%3D%28-1%29%5Ctimes%20%280%29+%281%29%5Ctimes%20%281%29+%28-0.5%29%20%5C%5C%20%5C%5C%5Ctherefore%20%5C%3B%20f_%7Bs_%7Boutput%7D%7D%280.5%29%3D1%20%5Cend%7Bmatrix%7D" alt="equation" /></p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Dengan pengiraan di atas, maka jelas lah multilayer perceptron boleh menyelesaikan masalah XOR ini. Tetapi mengapa algoritma neural network ini terkubur begitu lama sekali dan bagaimana ia akhirnya menjadi tumpuan para penyelidik semula. Cerita seterusnya akan saya bincangkan di artikel yang seterusnya,</p>
<p>InsyaAllah!</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="megatazm/MyDLBlog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/MyDLBlog/deep%20learning/2021/01/19/ml-perceptron.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/MyDLBlog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/MyDLBlog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/MyDLBlog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/MyDLBlog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/MyDLBlog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
