{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"visualization-curriculum-gF8wUgMm","language":"python","name":"visualization-curriculum-gf8wugmm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"2020-12-05-AI-ML-DL.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"0flFBM3BAx6g"},"source":["# Pengenalan Kepada AI, ML dan DL\n","> Perbincangan berkenaan Artificial Intelligent, Machine Learning dan Deep Learning.\n","\n","- toc: true \n","- badges: false\n","- comments: true\n","- categories: [deep learning]\n","- image: images/\n","- author: Megat Norulazmi"]},{"cell_type":"markdown","metadata":{"id":"YA2klSHUG17O"},"source":["Salam semua. Kita selalu mendengar perkataan “Artificial Intelligent” atau “AI”. Kalau masa awal-awal dulu kita rasa kembang hidung bila dapat mengguna perkataan ini dalam perbualan atau pun ceramah kita. Tapi, adakah setakat tahu menyebutnya sahaja sudah cukup? Tidak kah teringin untuk mengetahuinya dengan lebih mendalam? Ya, saya mahu! Anda bagaimana? Mari kita lakukan sedikit kajian. Maklumat di hujung jari anda!\n","\n","Selain daripada AI, mungkin juga anda pernah dengar terma Machine Learning (ML) atau Deep Learning (DL) kan. Sejak kebelakangan ini kerap sangat kita dengar tiga perkataan ini sinonim dengan terma Data Science lah Data Analytic lah kan? Di sini saya nak bincangkan berkenaan tiga terma yang popular ini. Apa bendanya AI, ML, dan DL ni? Ahh zaman sekarang ni apa pun google jer. "]},{"cell_type":"markdown","metadata":{"id":"wUt2gp44ajMG"},"source":["<!-- picture ai-ml-dl \n","![DL is subset of ML and AI](fastcore_imgs/ai-ml-dl.png)\n","-->\n","\n","<br/>\n","<br/>\n","<img src=\"fastcore_imgs/ai-ml-dl.png\" width=\"80%\" height=\"80%\" alt=\"DL is subset of ML and AI\">\n","<br/>\n","<br/>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NhOkrLlBbF_1"},"source":["Ohh! DL adalah subset ML dan subset AI. AI dalam bahasa melayunya “kecerdasan buatan” boleh dicapai melalui pelbagai teknik. ML adalah salah satu tekniknya yang popular di masa kini. Manakala DL adalah salah satu teknik algoritma ML yang sedang hangat diperkatakan. Selain DL ada banyak lagi algoritma-algoritma lain yang popular seperti SVM, XGBoost, Random Forest yang sangat bagus untuk data yang tersusun dalam bentuk tabular data atau pun database. DL pula sangat berkuasa untuk menyelesaikan isu berkaitan “*perceptual problem*” seperti data yang berkaitan dengan imej, video, suara, dan bahasa. \n","\n","Secara teorinya semakin banyak input data yang berkualiti dibekalkan, semakin baik prestasi outputnya. Namun, Gambarajah di bawah menunjukkan, prestasi algoritma tradisional seperti SVM, Random Forest, XGBoost akan mencapai takat tepu mendatar walaupun bekalan data yang di sumbat masuk semakin banyak. Sebaliknya, prestasi NN pula di lihat boleh ditingkatkan sejajar dengan jumlah input data yang semakin banyak."]},{"cell_type":"markdown","metadata":{"id":"FjUQk1l7aLlv"},"source":["<!--\n","![More data, DL perform better](fastcore_imgs/moredataDLbetter.png)\n","-->\n","\n","<br/>\n","<br/>\n","<img src=\"fastcore_imgs/moredataDLbetter.png\" width=\"50%\" height=\"50%\" alt=\"More data, DL perform better\">\n","<br/>\n","<br/>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bm20LwcVbOLR"},"source":["Ehh sekejap, ini algoritma NN (Neural Network), bukan DL (Deep Learning)!\n","\n","Pada yang tidak tahu, DL ini adalah nama branding terkini untuk NN yang di pelopori oleh Bapa Deep Learning, Geoffry Hinton. Apa tu Neural Network? mungkin anda tertanya-tanya kan. Takpa itu letak di tepi dulu, cuba lihat gambarajah di bawah."]},{"cell_type":"markdown","metadata":{"id":"dUdt8VRXa1_j"},"source":["<!-- \n","![shallow nn](fastcore_imgs/nnshallow.png)\n","-->\n","\n","<br/>\n","<br/>\n","<img src=\"fastcore_imgs/nnshallow.png\" width=\"100%\" height=\"100%\" alt=\"Shallow NN\">\n","<br/>\n","<br/>\n"]},{"cell_type":"markdown","metadata":{"id":"Rj35qe0UbR40"},"source":["Gambarajah architecture NN ini terdiri daripada 3 lapisan, iaitu:-\n","\n","\n","*   Lapisan Pertama, Input Layer beserta 3 node atau feature\n","*   Lapisan Kedua, Hidden Layer beserta 4 node atau feature\n","*   Lapisan Ketiga, 1 Output node.\n","\n","Ini merupakan contoh architecture asas NN yang sekarangnya dipanggil Shallow NN. Pada masa dahulu lebih kurang pada tahun 1950 - 1960, architecture Shallow NN sahaja lah yang mampu di capai, namun kemudiannya idea NN ini terkubur berdekad-dekad lamanya (kita akan bincangkan sejarah DL kemudian). Kini, architecture NN boleh di bina dengan lebih *Deep*, jumlah node dan lapisan yang lebih banyak dan kompleks. Secara teorinya semakin banyak node dan lapisan architecturenya maka semakin tinggi lah kerumitan masalah yang ia boleh selesaikan, tetapi semakin tinggi pula kuasa pemprosesan yang diperlukan.\n","\n","Ok. Sebelum kita menjebakkan diri ke dalam dunia DL, kenali ML terlebih dahulu."]},{"cell_type":"markdown","metadata":{"id":"dzSRUjwKm0TI"},"source":["# Machine Learning\n","\n","Machine learning jika diterjemahkan secara terus kepada bahasa melayu apa maksudnya? Mesin Belajar? Belajar Mesin? atau mungkin lebih tepat jika ia bermaksud mesin yang boleh di ajar. Mesin yang satu hari nanti boleh mengajar \"diri\"nya sendiri mungkin kedengaran menakutkan ataupun kelakar, tetapi menurut Elon Musk, jika penggunaan teknologi DL ini tidak di kawal-selia dengan baik ia mungkin bakal menjadi lebih bahaya daripada kepala bom nuklear!\n","\n","Ok, kenapa ML adalah teknik AI yang sangat hebat di waktu ini.\n","\n","Sebagai contoh, katakan kita nak mengajar komputer untuk mengenali haiwan yang dikenali oleh manusia sebagai kucing. Mungkin agak mudah mengajar bayi yang berumur 3 tahun untuk mengenalinya, tetapi bolehkah anda bayangkan bagaimana sukar untuk melakukannya melalui teknik traditional AI? Secara traditionalnya, untuk memberi arahan atau mengajar komputer membuat perbandingan, ia boleh dilaksanakan dengan pendekatan rule-based melalui programming ataupun pengaturcaraan. Seperti contoh, dengan berpandukan pada pixel-pixel gambar seekor kucing seperti di bawah, anda perlu memprogram ribuan kod rule-based yang kompleks untuk membolehkan komputer mengenali kucing tersebut. "]},{"cell_type":"markdown","metadata":{"id":"hZPg732ZlF6v"},"source":["<br/>\n","<br/>\n","<img src=\"fastcore_imgs/cat.jpg\" width=\"75%\" height=\"75%\" alt=\"cat\">\n","<br/>\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"ZvWNufuxopWB"},"source":["Bisa lakukannya? Ya mungkin boleh, berkat ketekunan dan kesabaran anda. Alhamdulillah selesai masalah.\n","\n","Tunggu! Tunggu sebentar! Masih awal untuk bergumbira. \n","\n","Cuba lihat gambar-gambar kucing di bawah. Bagaimana pula dengan kucing-kucing lain? ada ratus ribuan kucing di luar sana malahan berpuluh-puluh spesis kucing wujud di dunia ini. Bagaimana pula dengan keadaan kucing-kucing itu? ada yang sedang mengendap di tepi bakul, di urut tengkoknya, mulut mengiau luas, mendukung anaknya, dan sebagainya. "]},{"cell_type":"markdown","metadata":{"id":"Ax6ZIOjWodFz"},"source":["<br/>\n","<br/>\n","<img src=\"fastcore_imgs/cats.png\" width=\"100%\" height=\"100%\" alt=\"cats\">\n","<br/>\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"R_fDhgeQHfsd"},"source":["Dengan kata lain, bagaimana kita nak \"*generalize*\" kan kod rule-based ini supaya ia dapat mengenali kucing-kucing yang belum di \"lihat\" oleh komputer. Disinilah kekuatan ML mengatasi teknik traditional AI. Lihat gambarajah di bawah. Kaedah traditional programming, seperti yang dinyatakan di atas, ia memerlukan manusia membina program berdasarkan pada input data untuk menghasilkan model klasifikasi rule-based. Manakala, ML tidak memerlukan manusia untuk membina program tersebut secara eksplisit. Apa yang ML perlu ialah bantuan manusia melabelkan jawapan betul pada setiap input data, dan menyalurkankannya ke dalam komputer. Seterusnya, algoritma ML memproses data tersebut lalu membina model yang boleh mengklasifikasi data input yang belum di \"lihat\" sebagai kucing atau bukan kucing. Oleh kerana model klasifikasi tersebut boleh di bina secara automatik dan pantas oleh algoritma ML (dengan sedikit bantuan daripada manusia), kita boleh meningkatkan prestasi \"*generalization*\" model tersebut dengan menyumbat masuk pelbagai jenis gambar kucing kepada algoritma ML itu dengan skala yang besar (lebih banyak input data yang pelbagai, lebih tinggi prestasi *generalization* sebuah model)."]},{"cell_type":"markdown","metadata":{"id":"paMA42jy3-VV"},"source":["<br/>\n","<br/>\n","<img src=\"fastcore_imgs/traditionalprog.jpg\" width=\"100%\" height=\"100%\" alt=\"traditionalprog\">\n","<br/>\n","<img src=\"fastcore_imgs/mlmodel.jpg\" width=\"100%\" height=\"100%\" alt=\"mlmodel\">\n","<br/>\n","<br/>\n"]},{"cell_type":"markdown","metadata":{"id":"EJZQgVpIOYCq"},"source":["Secara informalnya, ML boleh didefinasikan sebagai:-\n","\n","<blockquote> Teknik AI yang membolehkan machine berupaya belajar tanpa perlu di program secara eksplisit </blockquote> \n","\n","Secara formalnya pula ia didefinasikan sebagai:-\n","\n","<blockquote> Suatu program komputer dikatakan belajar dari pengalaman E terhadap suatu kelas tugasan T dengan prestasinya di ukur dengan P. Prestasi pada ukuran P terhadap tugasan T meningkat melalui penambahan pengalaman E. </blockquote> \n","\n","Definasi E, T & P dengan frasa lebih mudah:-\n","\n","*   T = Tugasan untuk mengenali kucing di dalam gambar\n","*   E = Pengalaman melihat banyak gambar-gambar kucing\n","*   P = Kebarangkalian program mengenal pasti kucing di dalam gambar\n","\n","Untuk pengetahuan anda, ML terdiri dari beberapa kategori; iaitu *Supervised Learning, Unsupervised Learning, Semi-Supervised Learning, Self-Supervised Learning, Reinforcement Learning*, dan banyak lagi. Cuma kali ini, kita fokus pada teknik yang saya bincangkan di atas iaitu, Supervised Learning. Supervised Learning sangat mustajab digunakan untuk menyelesaikan masalah berkaitan *Classification* dan *Regression* (Saya akan jelaskan hal berkenaan regression kemudian).\n","\n","Secara analoginya, *Supervised Learning Classification* adalah ibarat mengajar kanak-kanak mengenal kucing menggunakan kad flip. \n","\n","*   Cikgu: Ini apa? <br/>\n","*   Murid: Itu ayam. <br/>\n","*   Cikgu: Bukan, Ini kucing. <br/>\n","*   Murid: Itu kucing. <br/>\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gnhlSloZICnn"},"source":["# Supervised Learning\n","\n","Seperti yang dinyatakan sebelum ini, idea *supervised learning classification* adalah berdasarkan pada konsep mengajar kanak-kanak (murid) menggunakan kad flip. \n","\n","\n","*   Cikgu = Supervisor \n","*   Murid = Komputer\n","*   Input Data = Gambar Kucing\n","*   Input Label = Kapsyen pada Kad Flip\n","\n","Gambarajah di bawah menunjukkan aliran proses *supervised learning*."]},{"cell_type":"markdown","metadata":{"id":"iH4ljU8kNur1"},"source":["<br/>\n","<br/>\n","<img src=\"fastcore_imgs/supervisedlearning.png\" width=\"100%\" height=\"100%\" alt=\"supervised learning\">\n","<br/>\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"phekMe_FaBET"},"source":["Langkah pertama untuk menjalankan proses Supervised Learning (SL) adalah mengumpul dan melabel atau menganotasi data. Kita bernasib baik sebab gambar-gambar kucing sudah pun ada banyak di google.com, mudah lah untuk kita mencuba ML dan DL nanti. Kita bukan sahaja boleh mendapatkan data daripada google.com dan [Google Dataset Search](https://https://datasetsearch.research.google.com/), ada banyak *benchmark data* yang telah digunakan oleh penyelidik-penyelidik, ada di internet. Senarai dataset tersebut boleh di perolehi di sini, [TowardsAI](https://medium.com/towards-artificial-intelligence/best-datasets-for-machine-learning-data-science-computer-vision-nlp-ai-c9541058cf4f) dan [Wikipedia](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research).\n","\n","Ini adalah suatu kemudahan kan? banyak data sudah sedia ada untuk memberi galakan kepada anda menerokai teknologi ini (Anda masih perlu melakukan sedikit proses penyesuaian data, ianya agak mudah dilakukan).\n","\n","##Data Preprocessing\n","\n","Namun, jika anda ingin mengunakan ML untuk menyelesaikan permasalahan sebenar di luar sana, pengumpulan dan penyediaan datanya tidak lah semudah itu. Anda perlu melalui proses *Data Pre-processing* terlebih dahulu.\n","\n","*   Data Cleaning\n"," - Missing Data \n","     - Contohnya, jika ada atribut rekod di dalam data tersebut hilang, padamkan rekod itu.\n","     - Ataupun simpan rekod itu, tetapi nilai pada atribut yang hilang digantikan dengan nilai average atribut. (Rekod dan atribut adalah satu jaluran informasi dalam data)\n","    - Jika data tersebut adalah imej, kita boleh membuang data yang tidak sesuai secara visual sebelum atau secara automatik selepas training. *Fastai* adalah framework deep learning untuk *Pytorch*, mempunyai fitur untuk menyenaraikan data yang tidak baik secara automatik selepas menjalankan proses *training*.\n"," - Noisy Data\n","      - *Noisy data* adalah data yang dikatakan \"*meaningless*\", \"*takda maknanya*\". Macam bunyi noise + muzik, bunyi noise itu kalau tak ada lagi sedap bunyi muziknya. Ia boleh diuruskan melalui teknik seperti *Binning*, *Regression*, dan *Clustering* (melandaikan data, mengurangkan zig-zag). Ada juga yang mencadangkan dengan menambahkan lebih banyak data yang berkualiti untuk mengurangkan kesan *noisy data*. Kaedah-kaedah lain adalah seperti teknik *dimension reduction* (seperti algoritma PCA), teknik *Regularization*, dan *Cross Validation*. Ironinya noise (random noise) merupakan rakan baik untuk algoritma DL. Contohnya, random noise sengaja di suntik masuk ke dalam data (teknik *Data Augmentation*) sebelum ia disalurkan ke dalam algoritma DL regression untuk meningkatkan tahap *generalization* modelnya (salah satu teknik *Regularization* dalam DL). Manakala algoritma DL Generative Adversarial Network (GAN) pula menggunakan random noise sebagai dasar untuk mencipta \"*fake face images*\", muka manusia tiruan.\n"," - Outlier Data\n","     - *Outlier data* adalah data yang berada jauh daripada kelompok data lain dari segi kesamaan dan keberkaitannya. Kebiasaannya *outlier data* perlu di buang (mungkin disebabkan *human error*), namun ada ketikanya seperti untuk *anomaly detection* (mengesan sesuatu di luar kebiasaan seperti aktiviti hacker, network intrusion, dan penipuan dalam talian), dalam konteks ini *outlier data* adalah penting.\n","*   Data Transformation\n"," - Normalization\n","      - Normalization menyeragamkan skala nilai pada setiap atribut di rekod. Kebanyakkan algoritma memerlukan semua atribut tersebut diseragamkan di antara julat yang sama. Contohnya, jika julat atribut *Harga Rumah* adalah 50,000 dan 500,000 dan julat atribut *Jumlah Bilik* adalah 2 dan 8 (Contoh atribut data berkenaan hartanah), ia perlu diseragamkan di dalam julat yang sama untuk membolehkan algoritma berfungsi dengan baik.  Algoritma seperti NN sebagai contoh, memerlukan input data yang diseragamkan kepada nilai di antara 0 dan 1. \n"," - Discretization\n","     - Menukarkan julat nombor tertentu kepada perkataan. Contohnya, nilai antara 1 dan 17 -> Kanak-Kanak, 18 dan 39 -> Dewasa, 40 dan 59 -> Pertengahan, 60 dan ke atas -> Wargamas.\n"," - Encoding Categorical Value\n","     - mengekod nilai atribut dari perkataan kepada nombor binary. Contoh, Kucing -> 100, Ayam -> 010, dan Monyet -> 001. Ini perlu dilakukan terutamanya untuk algoritma seperti NN yang hanya boleh berfungsi dengan nilai input, outputnya di dalam bentuk nombor sahaja.\n","    - Data Labeling\n","     - Data labeling atau annotation yang diperkatakan di atas juga adalah teknik data preprocessing yang mesti dilakukan sebelum proses supervised learning. Jika data tersebut adalah imej, anda perlu menanda pada imej tersebut, objek yang ingin diklasifikasikan. Bayangkan jika anda perlu menganotasikan pada 50 ribu keping gambar yang mana setiap keping gambar itu ada 1000 orang!\n","*   Data Dimension Reduction\n"," - Feature Extraction\n","      - Memilih atribut-atribut yang relevan dan menggabungkannya menjadi satu atribut yang baharu.\n"," - Feature Selection\n","      - Memilih atribut yang relevan dan membuang atribut yang tidak relevan. \n","    - Kedua-dua teknik ini bukan sahaja mengurangkan dimensi data, ia juga dikatakan akan menjadikan data tersebut lebih bermakna dan mudah di latih oleh algoritma ML. Ada banyak algoritma yang boleh digunakan untuk *data dimension reduction* ini, tapi saya tak membincangkannya di sini kerana algoritma DL yang kita akan terokai nanti dikatakan mampu beraksi dengan baik tanpa perlu melalui proses ini dilakukan secara manual.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HEXP2M-d4Z6J"},"source":["## Model Training\n","\n","Apakah yang dimaksudkan dengan *model training*? \n","\n","Graf di bawah menunjukkan hubungan antara dua pemboleh ubah X, Y dan garisan persamaan linear di garis melintasi data yang diplotkan. Proses ini dikenali sebagai *Simple Linear Regression Model*, contoh ini adalah yang paling mudah kita gunakan kerana ia hanya melibatkan dua pemboleh ubah (atribut 2 dimensi). Bulatan kuning adalah training data manakala garisan biru adalah model yang digariskan oleh algoritma ML melalui proses *training*. Anak panah berwarna merah merupakan jarak atau *error* antara training data dan nilai pada garisan model f(X)->Y. Melalui proses training, algoritma ML perlu membina garisan model f(X)->Y yang minima jumlah *error*nya berbanding dengan point training data (seperti yang ditunjukkan pada graf sebelah kanan)."]},{"cell_type":"markdown","metadata":{"id":"e0-RlbUO4AZs"},"source":["<br/>\n","<br/>\n","<img src=\"fastcore_imgs/trainingmodel.png\" width=\"100%\" height=\"100%\" alt=\"trainingmodel\">\n","<br/>\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"kU6jno1oPN4b"},"source":["Rumus di bawah adalah persamaan linear yang merujuk pada garisan yang berwarna biru. \n","<br/>\n","<br/>\n","![equation](https://latex.codecogs.com/png.download?%5CLARGE%20Y%3DaX+b)\n","<br/>\n","Nilai pemboleh ubah *a* menentukan kecerunan, manakala pemboleh ubah *b* menentukan ketinggian garisan tersebut pada paksi Y. Graf di sebelah kiri merupakan garisan permulaan model *linear regression* itu pada ketika *a=0* dan *b=1*. Pada ketika ini nilai prediksi model f(X) -> Y pada setiap titik x training data adalah 1. Jumlah error ketika ini boleh di hitung dengan menggunakan rumus *Mean Square Error (MSE)*. "]},{"cell_type":"markdown","metadata":{"id":"bvbkIMKQAjFF"},"source":["<br/>\n","<img src=\"fastcore_imgs/mse.png\" width=\"10%\" height=\"10%\" alt=\"mse\">\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"fmQsyEQYCJwW"},"source":["Merujuk pada rumus MSE di atas:\n","\n","* *x* adalah *independant variable* ataupun input fitur yang digunakan oleh model untuk melakukan prediksi nilai *dependant variable* ataupun *target value*, *y*. \n","* *prediction(x)* adalah nilai prediksi *y* di input *x* berdasarkan model linear regression ketika di suatu nilai *a* dan *b*.\n","* *D* adalah training data yang telah dilabelkan. *x* ialah input fitur manakala *y* ialah output labelnya. Contoh graf di atas menunjukkan ada 6 data point dengan input fitur dan label seperti berikut:- \n","> *(x1,y1), (x2,y2), (x3,y3), (x4,y4), (x5,y5), (x6,y6)*\n","* *N* adalah jumlah training data (contoh di atas, *N* = 6).\n","\n"," Untuk menghitung MSE, pada setiap data point, dapatkan *error* antara nilai y label dan y prediksi, kemudian kuasa duakannya. Lakukan ini pada setiap data point, kemudian jumlahkan kesemuanya. Akhir sekali, bahagikan hasil jumlah tersebut dengan jumlah training data, *N* (merujuk pada contoh di atas, *N* = 6)"]},{"cell_type":"markdown","metadata":{"id":"A9QHj3R_iEwz"},"source":["Proses yang merujuk pada graf di kiri itu adalah dikatakan sebagai \"*initial iteration per 1 epoch*\". Apa maksudnya?\n","\n","*Initial* di sini bermaksud nilai permulaan parameter *a* dan *b* bagi mengariskan kedudukan awal garisan model linear tersebut. Nilai *a* dan *b* itu boleh ditentukan supaya bermula dengan nilai kosong ataupun nilai random (Untuk architecture NN yang kompleks kita mungkin perlu menggunakan kaedah lain yang lebih spesifik).\n","\n","*Iteration* adalah frekuensi algoritma ML itu disuapi sebahagian daripada training data. Epoch pula adalah frequency kesemua training data itu selesai di proses oleh algoritma ML tersebut. \n","\n","Boleh faham tak? Pening? Macam tak ada beza pun maksud ayat di atas. \n","\n","Ok. Dalam keadaan sebenar, kesemua training data tidak di suap masuk ke dalam algoritma secara serentak. Ia di suap mengikut kumpulan atau *batch*. Contoh, jika jumlah training data adalah 2000 (1 epoch = 2000 data di proses). Jika anda setkan saiz batch = 100, maka setiap 1 epoch = 20 iteration (20 x 100 = 2000). Jika anda setkan training proses sebanyak 250 epoch maka total iterationnya adalah 20 x 250 = 5000. Ingat, pengiraan MSE berlaku pada setiap iteration. Macam mana, Ok?\n","\n","Untuk contoh di atas, oleh kerana training datanya cuma ada 6 sahaja, maka setiap 1 epoch ada 1 iteration sahaja (kita setkan saiz batch = jumlah training data, iaitu 6). Oleh itu pada setiap 1 iteration nilai MSE di hitung berdasarkan pada kedudukan terkini garisan linear model. Kedudukan garisan linear model akan berubah pada setiap iteration. Dengan harapan nilai MSEnya semakin kecil.\n","\n","Apa yang akan berlaku jika anda setkan training proses sebanyak 250 epoch? Cukup ker?\n","\n","Maksudnya, algoritma ML tersebut ada masa sebanyak 250 iteration untuk mengariskan linear regression modelnya (melalui kombinasi nilai parameter *a* dan *b*) supaya MSE mencapai nilai seminima yang mungkin. Secara teorinya, lagi lama iteration maka semakin tinggilah peluangnya mencapai nilai MSE yang paling minima. Namun ini bergantung kepada keupayaan algoritma ML menentukan nilai parameter *a* dan *b* yang optimum dalam jangkamasa yang singkat. Bayangkan jika algoritma itu menggunakan teknik random bagi menentukan nilai parameter *a* dan *b* itu. Iteration sebanyak 250 mungkin tidak mencukupi kan? \n","\n","> Algoritma Deep Learning menggunakan teknik yang di panggil \"Gradient Decent\" untuk mencapai nilai MSE yang minima, jauh lebih pantas berbanding teknik secara random. \n","\n","Bayangan bukan 2, tapi ada beribu parameter yang perlu ditentukan? Anda mungkin perlu menunggu selama beribu-ribu tahun!"]},{"cell_type":"markdown","metadata":{"id":"8JlUo6UoRJI1"},"source":["## Model Testing\n","\n","Model testing atau Model inferencing"]},{"cell_type":"markdown","metadata":{"id":"5-NHzTHbT2AA"},"source":["## Model Tuning\n","\n","Model parameter dan hyperparameter tuning\n"]}]}