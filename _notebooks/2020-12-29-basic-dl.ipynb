{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2020-12-29-basic-dl.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPiXKDMLJLyvIZ4XNYaPbU0"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sz_uQONCoQW7"},"source":["# Pengenalan Kepada Deep Learning\n","> Perbincangan berkenaan konsep asas deep learning\n","\n","- toc: true \n","- badges: false\n","- comments: true\n","- categories: [deep learning]\n","- image: images/\n","- author: Megat Norulazmi"]},{"cell_type":"markdown","metadata":{"id":"ReYmjuFcpi_v"},"source":["Assalamualaikum. Selamat berjumpa kembali.\n","\n","Seperti yang saya maklumkan pada [artikel yang lepas](https://megatazm.github.io/MyDLBlog/deep%20learning/2020/12/23/AI-ML-DL.html), saya telah berjanji untuk cuba memberikan sedikit penerangan asas berkenaan teori DL ini. Kalau nak diikutkan, jika kita menggunakan library tensorflow atau pytorch nanti, kesemua yang kita bincang ini akan diabstrakkan implementasinya. \n","\n","Dengan kata lain, \"Tak payah tau pun, pakai jer\". \n","\n","Tapi saya rasa anda perlu tahu juga konsep asasnya terlebih dahulu, sebab ini akan membantu anda untuk majukan ke tahap penggunaan DL yang lebih kompleks. Lagipun, tak kanlah nak pakai jer library Tensorflow atau Pytorch membuta tuli kan?"]},{"cell_type":"markdown","metadata":{"id":"BfobCvuKM1fT"},"source":["# Perceptron\n","***Perceptron*** adalah salah satu *architecture* ***ANN***   yang paling asas, dicipta pada tahun 1957 oleh Frank Rosenblatt. Ia berdasarkan pada konsep *neuron* (lihat gambar di bawah) yang disebut ***Treshold Logic Unit*** (TLU), ataupun ***Logic Treshold Unit*** (LTU). Nilai input dan outputnya adalah nombor (bukan nilai on/off binari), dan setiap sambungan di antara input nod dan output nod itu diberikan nilai pemberat atau ***weight***. Secara analoginya, lagi besar *weight* maka lagi tebal lah wayar sambungannya (Lagi besar pengaruhnya). "]},{"cell_type":"markdown","metadata":{"id":"Da_Z9aQwUfCH"},"source":["<br/>\n","<br/>\n","<img src=\"fastcore_imgs/perceptron.png\" width=\"80%\" height=\"80%\" alt=\"perceptron\">\n","<br/>\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"GSv_9xoWCCmG"},"source":["TLU menghitung jumlah *weight* beserta dengan inputnya seperti yang ditunjukkan oleh rumus di bawah,\n","<br/>\n","<br/>\n","![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B100%7D%20%5Cfn_phv%20%5Clarge%20z%3D%20w_%7B1%7Dx_%7B1%7D%20+%20w_%7B2%7Dx_%7B2%7D%20+..+%20w_%7Bn%7Dx_%7Bn%7D%20%3D%20x%5E%7BT%7Dw)\n","<br/>\n","\n","kemudian hasil ***z*** itu diaplikasikan kepada fungsi ***step(z)*** untuk menhasilkan nilai output yang baharu,\n","<br/>\n","<br/>\n","![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B100%7D%20%5Cfn_phv%20%5Clarge%20hw%28x%29%3Dstep%28z%29%2C%20where%5C%20z%3Dx%5E%7BT%7Dw)\n","<br/>\n","\n","Menyingkap kembali pada artikel yang [sebelum ini](https://megatazm.github.io/MyDLBlog/deep%20learning/2020/12/23/AI-ML-DL.html), ia masih menggunakan rumus yang sama iaitu ***y = ax + b*** tanpa pembolehubah ***b***. Merujuk pada ini, ada sedikit perbezaan iaitu nilai output adalah hasil dari 3 input fitur ***x*** dengan nilai pengaruh weight ***w*** (dahulunya ***a***) pada setiap fitur tersebut. Perbezaan yang paling utama adalah peranan ***Step Function*** ataupun \"***Activation Function***\" (terma yang digunakan dalam DL) tersebut. Idea *activation function* ini penting untuk membolehkan kita membina model yang ***non-linear***. Kenapa kita perlukan model *non-linear*? Cuba ingat balik fakta dari artikel yang lepas, garisan ***linear*** hanya mampu menghasilkan suatu model yang ***underfit*** atau ***high bias***. Ini bukan suatu model yang kita inginkan untuk menyelesaikan masalah yang kompleks."]},{"cell_type":"markdown","metadata":{"id":"50cMmuivJAOD"},"source":["Mungkin ada yang tertanya-tanya kenapa ada huruf *superscript* ***T*** di atas huruf ***x*** itu?\n","<br/>\n","<br/>\n",">![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B100%7D%20%5Cfn_phv%20%5Clarge%20x%5E%7BT%7Dw)\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"809U3ai_UYKh"},"source":["Ini kerana ia melibatkan pengiraan menggunakan *Matrix Multiplication*. Janganlah rasa takut bila dengar terma matrix ini. Anda hanya perlu tahu asas berkenaan ilmu matematik *matrix* yang di pelajari di sekolah menengah. Lagipun semua pengiraan ini nanti akan dilakukan oleh library Tensorflow atau Pytorch. \n","\n","Ok. Huruf ***T*** adalah merujuk kepada proses matrix yang di panggil ***Transpose***. Ia diperlukan untuk membetulkan bentuk dimensi matrix ***x*** bagi membolehkan ia multiply dengan matrix ***w***. Contoh, jika bentuk dimensi matrix ***x*** dan ***w*** adalah ***(3,1)***, operasi matrix dimensi ***x(3,1) x w(3,1)*** itu perlu ditukarkan ke bentuk ***x(1,3) x w(3,1)*** terlebih dahulu dengan melakukan proses transpose pada matrix ***x***.\n","\n","Jika anda sudah lupa berkenaan operasi asas matrix, bolehlah rujuk kembali pada buku SPM anda. InsyaAllah, sayang anda pada cikgu matematik akan bertambah. "]},{"cell_type":"markdown","metadata":{"id":"mllUUhOqI1S-"},"source":["Ok. Apa itu Step Function?\n","<br/>\n","![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B100%7D%20%5Cfn_phv%20%5Clarge%20heaviside%28z%29%3D%5Cbegin%7Bcases%7D%20%26%20%5Ctext%7B0%20if%20%7D%20z%3C%200%20%5C%5C%20%26%20%5Ctext%7B1%20if%20%7D%20z%5Cgeq%200%20%5Cend%7Bcases%7D)\n","<br/>\n","<br/>\n","![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B100%7D%20%5Cfn_phv%20%5Clarge%20sgn%28z%29%3D%5Cbegin%7Bcases%7D%20%26%20%5Ctext%7B%20-1%20if%20%7D%20z%3C%200%20%5C%5C%20%26%20%5Ctext%7B%20%5C%200%20if%20%7D%20z%3D%200%20%5C%5C%20%26%20%5Ctext%7B+1%20if%20%7D%20z%3E%200%20%5Cend%7Bcases%7D)\n","<br/>"]}]}