{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021-01.-11-perceptron-ml-sklearn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMyA5IWlgwk8v2quEksjKP4"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-vD1BOA95610"},"source":["# Mengaplikasikan Perceptron Dengan Scikit-learn Library\n","\n","> Perbincangan berkenaan penggunaan perceptron menggunakan sklearn library dan python\n","\n","- toc: false \n","- badges: true\n","- comments: true\n","- categories: [deep learning]\n","- image: images/\n","- author: Megat Norulazmi"]},{"cell_type":"markdown","metadata":{"id":"jDhFfOOg_8Ul"},"source":["Assalamualaikum dan selamat berjumpa kembali.\n","\n","Seperti yang telah saya nukilkan pada [artikel yang lepas](https://megatazm.github.io/MyDLBlog/deep%20learning/2020/12/29/basic-dl.html), saya telah menerangkan dengan serba ringkas berkenaan mekanisma perceptron dan menunjukkan contoh penggunaan mudah perceptron menggunakan sklearn library (ataupun scikit-learn). Di artikel ini, saya akan menulis penggunaan perceptron dengan aturan proses machine learning yang lebih lengkap daripada sebelum ini. \n","\n","Untuk kali ini, saya masih menggunakan sklearn library. Mungkin ada yang berkata-kata, \n",">\"Asyik sebut-sebut keras, tensorflow dan pytorch jer sebelum ini, tapi tak pakai-pakai pun\". \n","\n","InsyaAllah saya cuba perkenalkan asas penggunaanya di artikel yang seterusnya ya.\n","\n","Berikut adalah pecahan proses yang kita akan lakukan pada kali ini:-\n","\n","1.   Import library sklearn yang diperlukan\n","2.   Menghasilkan data buatan menggunakan library sklearn **make_classification**\n","3.   Bina perceptron menggunakan library sklearn **Perceptron**\n","4.   Melakukan model validation dengan stratified k-fold cross validation menggunakan library sklearn **RepeatedStratifiedKFold**\n","5.   Train model perceptron menggunakan data buatan tersebut \n","6. Melakukan hyperparameter tuning untuk learning rate dan kekerapan iteration melalui sklearn library **GridSearchCV**\n","7. Memaparkan prestasi validation model tersebut berdasarkan pada kombinasi beberapa nilai learning rate dan iteration yang berbeza.\n","8. Menguji prestasi model menggunakan test data dengan kombinasi learning rate dan kekerapan iteration pilihan yang terbaik, kemudian memaparkan prestasi ketepatannya.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EqGOt3fhmAgm"},"source":["Pertama sekali, import library yang bakal kita gunakan,\n","\n","*   make_classification - Fungsi untuk menghasilkan data buatan\n","*   GridSearchCV - Fungsi untuk melakukan hyperparameter tuning\n","*   RepeatedStratifiedKfold - Fungsi untuk menjalankan stratified k-fold cross validation yang boleh ditentukan kekerapan ulangan.\n","*  Perceptron - Fungsi untuk membina architecture algoritma perceptron"]},{"cell_type":"code","metadata":{"id":"_HW67kE7mKCV","executionInfo":{"status":"ok","timestamp":1610515765879,"user_tz":-480,"elapsed":936,"user":{"displayName":"Azmi Megat","photoUrl":"","userId":"09952198438441952493"}}},"source":["# import sklearn library yang akan digunakan\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.linear_model import Perceptron"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1pSWqMJGn_BP"},"source":["Tujuan kita menggunakan fungsi make_classification ini adalah menghasilkan data yang sesuai untuk perceptron melakukan klasifikasi binari. Ini kerana perceptron hanya mampu melakukan klasifikasi pada data yang \"***linearly separable***\", iaitu data yang mudah diasingkan kepada dua kelas dengan menggunakan satu garisan linear. Fungsi make_classification ini juga boleh digunakan untuk menghasilkan pelbagai jenis data klasifikasi yang kompleks. Ia sangat berguna untuk menguji prestasi dan melakukan perbandingan di antara pelbagai jenis algoritma klasifikasi yang lama dan baharu. Penerangan berkenaan penggunaan fungsi ini boleh di rujuk di [sini](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html). Bagi tujuan contoh ini, kita hanya akan menggunakan parameternya yang berikut,\n","\n","*   **n_samples** - Untuk menentukan jumlah instance atau rekod. Di sini saya setkan dengan nilai n_samples=1000.\n","*   **n_feature** - Untuk menentukan jumlah input fitur. Di sini saya setkan n_feature=10\n","*   **n_informative** - Untuk menentukan samada input fitur yang telah ditetapkan jumlahnya sebentar tadi adalah berinformatif. Nilai tetapannya mestilah tidak melebihi dengan nilai n_feature. Di sini saya setkan nilai n_informative = 10\n","* **n_redundant** - Oleh kerana kita telah menetapkan kesemua 10 feature kita adalah informatif maka di sini n_redundant = 0. Jika contohnya kita setkan n_redundant = 5, maka mestilah nilai n_informative=5 kerana total fitur adalah 10 (jika n_informative=4, n_redundant = 5, maka fitur selebihnya secara default disetkan sebagai noise). Lagi tinggi fitur informatif maka lagi mudahlah model perceptron itu di latih dan memperolehi ketepatan ramalan yang tinggi.\n","* **random_state** - Jujukan data instance atau rekod yang akan dihasilkan nanti adalah random. Namun, untuk memastikan data random ini adalah \"*reproducible*\", maksudnya untuk memastikan data ini sentiasa sama jika kita menghasilkannya berulang kali. Oleh itu, anda perlu setkan nilai integer yang sama pada random_state itu. Seperti contoh, di sini saya setkan random_state = 1.\n","\n"]},{"cell_type":"code","metadata":{"id":"4ofWtKtapTqx","executionInfo":{"status":"ok","timestamp":1610515768694,"user_tz":-480,"elapsed":1175,"user":{"displayName":"Azmi Megat","photoUrl":"","userId":"09952198438441952493"}}},"source":["# Menghasilkan dataset buatan. Cuba awak run kod ini berkali-kali. Hasilnya \n","# tetap sama kan? Cuba tukar nilai random_state=2, kemudian run. Sama juga ker?\n","X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n","\n","#uncomment ini untuk lihat data yang terhasil\n","#print (X, y)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YTDnQkvApdU6"},"source":["Untuk membina architecture NN perceptron, kita menggunakan fungsi perceptron dari library sklearn (tak perlu bina \"*from scratch*\"). Fungsi ini juga ada banyak setting parameternya. Anda boleh rujuk di [sini](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html?highlight=perceptron#sklearn.linear_model.Perceptron). Tapi, untuk contoh ini kita gunakan setting default sahaja. Setting parameter learning rate dan iteration pada fungsi perceptron ini akan kita lakukan melalui fungsi GridSearchCV. Hasilnya di simpan di dalam variable ***model***."]},{"cell_type":"code","metadata":{"id":"E_KFq5AIppCN","executionInfo":{"status":"ok","timestamp":1610515771003,"user_tz":-480,"elapsed":1085,"user":{"displayName":"Azmi Megat","photoUrl":"","userId":"09952198438441952493"}}},"source":["# Bina NN default perceptron\n","model = Perceptron()"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HAJLG7GLpsJE"},"source":["Sebelum menjalankan proses training dengan stratified k-fold cross validation (Saya ada berikan penerangan berkenaan proses ini di [artikel](https://megatazm.github.io/MyDLBlog/deep%20learning/2020/12/23/AI-ML-DL.html) yang pertama), kita perlu tetapkan nilai parameter pada fungsi RepeatedStratifiedKFold terlebih dahulu. Fungsi ini hanya ada 3 parameter sahaja yang perlu ditentukan nilainya. Penerangan lengkapnya ada di [sini](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html?highlight=repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold). Setting parameternya adalah seperti berikut,\n","\n","*   n_splits - Adalah untuk menentukan nilai k. Dalam contoh ini, saya setkan k=10 (n_splits=10), bermaksud data ini akan diasingkan sebanyak 10 bahagian (9 data training dan 1 data testing)\n","*   n_repeats - Menetapkan kekerapan proses 10-fold cross validation yang ingin di ulangi. Saya setkan n_repeats=3.\n","*  random_state - Saya rasa anda boleh agak tujuan parameter ini kan? Bagus! anda memang bijak.\n","\n","Hasil tetapan ini kemudiannya di simpan di variable ***cv***."]},{"cell_type":"code","metadata":{"id":"TeabeW6Ap1P5","executionInfo":{"status":"ok","timestamp":1610515772874,"user_tz":-480,"elapsed":903,"user":{"displayName":"Azmi Megat","photoUrl":"","userId":"09952198438441952493"}}},"source":["# tetapkan setting model validation stratified k-fold cross validation\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bnJtp2Cvp5Gx"},"source":["Di sini kita tetapkan konfigurasi hyperparameter tuning yang ingin dijalankan ke dalam variable ***grid***. Di contoh ini, saya hanya tetapkan parameter '**max_iter**' untuk iteration dan '**eta0**' untuk learning rate sahaja, setiap satunya dengan 5 nilai-nilai yang berbeza (parameter 'max_iter dan 'eta0' ini adalah berdasarkan pada tetapan parameter yang di sokong oleh fungsi perceptron( )). Akhir sekali, di fungsi GridSearchCV, masukkan variable **model**, **grid** dan **cv** yang telah kita konfigurasikan tadi ke tempat yang betul dengan tetapan parameter yang lain seperti **scoring='accuracy'** untuk memaparkan ketepatan prestasinya dan parameter **n_jobs=-1** supaya pemprosesan ini menggunakan kesemua cpu yang ada di komputer. Hasil tetapan fungsi GridSearchCV ini kemudiannya di simpan ke dalam variable ***search***."]},{"cell_type":"code","metadata":{"id":"k2J14s9ep9J0","executionInfo":{"status":"ok","timestamp":1610515775085,"user_tz":-480,"elapsed":929,"user":{"displayName":"Azmi Megat","photoUrl":"","userId":"09952198438441952493"}}},"source":["# set grid nilai-nilai pada parameter dengan dictionary data structure\n","grid = dict()\n","grid={'max_iter':(1, 10, 100, 1000, 10000),'eta0':(0.0001, 0.001, 0.01, 0.1, 1.0)}\n","# Jalankan training melalui proses cross validation setting cv\n","# dan melalui kombinasi 5 nilai pada max_iter dan eta0 tersebut\n","search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0iNx2Rn9qICM"},"source":["Melalui variable ***search***, train model klasifikasi perceptron ini menggunakan data buatan yang telah di jana. Hasil dapatan dari proses training ini akan di simpan di dalam variable ***results***."]},{"cell_type":"code","metadata":{"id":"Yvysir2eqOQO","executionInfo":{"status":"ok","timestamp":1610515780324,"user_tz":-480,"elapsed":3738,"user":{"displayName":"Azmi Megat","photoUrl":"","userId":"09952198438441952493"}}},"source":["# train model dengan cross validation, beserta kombinasi pelbagai \n","# nilai learning rate dan iteration dan pulangkan hasil dapatan\n","# di variable results\n","results = search.fit(X, y)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1I90VA30qgiD"},"source":["Melalui variable results tadi, dengan mudahnya kita boleh mempamirkan maklumat,\n","\n","*   Purata prestasi ketepatan ramalan terbaik\n","*   Kombinasi learning rate & iteration terbaik\n","*   Senarai lengkap purata prestasi ketepatan ramalan dengan setiap kombinasi learning & iteration. \n","\n","Merujuk pada maklumat yang dipaparkan di bawah, ketepatan tertinggi adalah **85.7%** manakala kombinasi parameter learning rate & iteration terbaik yang dicadangkan adalah **eta0=0.0001** (lagi besar learning rate lagi cepat proses training selesai) &  **max_iter=10** (lagi kurang iteration, lagi cepat proses training selesai)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGMxXOKfqtPB","executionInfo":{"status":"ok","timestamp":1610515780326,"user_tz":-480,"elapsed":1247,"user":{"displayName":"Azmi Megat","photoUrl":"","userId":"09952198438441952493"}},"outputId":"8bbf38cd-a921-4193-ff68-47f53779336c"},"source":["# summarize\n","print('Mean Accuracy: %.3f' % results.best_score_)\n","print('Config: %s' % results.best_params_)\n","# summarize all\n","means = results.cv_results_['mean_test_score']\n","params = results.cv_results_['params']\n","for mean, param in zip(means, params):\n","    print(\">%.3f with: %r\" % (mean, param))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Mean Accuracy: 0.857\n","Config: {'eta0': 0.0001, 'max_iter': 10}\n",">0.850 with: {'eta0': 0.0001, 'max_iter': 1}\n",">0.857 with: {'eta0': 0.0001, 'max_iter': 10}\n",">0.857 with: {'eta0': 0.0001, 'max_iter': 100}\n",">0.857 with: {'eta0': 0.0001, 'max_iter': 1000}\n",">0.857 with: {'eta0': 0.0001, 'max_iter': 10000}\n",">0.850 with: {'eta0': 0.001, 'max_iter': 1}\n",">0.857 with: {'eta0': 0.001, 'max_iter': 10}\n",">0.857 with: {'eta0': 0.001, 'max_iter': 100}\n",">0.857 with: {'eta0': 0.001, 'max_iter': 1000}\n",">0.857 with: {'eta0': 0.001, 'max_iter': 10000}\n",">0.850 with: {'eta0': 0.01, 'max_iter': 1}\n",">0.846 with: {'eta0': 0.01, 'max_iter': 10}\n",">0.853 with: {'eta0': 0.01, 'max_iter': 100}\n",">0.853 with: {'eta0': 0.01, 'max_iter': 1000}\n",">0.853 with: {'eta0': 0.01, 'max_iter': 10000}\n",">0.850 with: {'eta0': 0.1, 'max_iter': 1}\n",">0.836 with: {'eta0': 0.1, 'max_iter': 10}\n",">0.847 with: {'eta0': 0.1, 'max_iter': 100}\n",">0.847 with: {'eta0': 0.1, 'max_iter': 1000}\n",">0.847 with: {'eta0': 0.1, 'max_iter': 10000}\n",">0.850 with: {'eta0': 1.0, 'max_iter': 1}\n",">0.836 with: {'eta0': 1.0, 'max_iter': 10}\n",">0.847 with: {'eta0': 1.0, 'max_iter': 100}\n",">0.847 with: {'eta0': 1.0, 'max_iter': 1000}\n",">0.847 with: {'eta0': 1.0, 'max_iter': 10000}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wSjKRBrjLoIO"},"source":["Ok. Mari kita cuba train model ini semula dengan kombinasi learning rate & iteration yang terbaik, kemudian mengujinya dengan test data. Bagaimana? boleh dapat prestasi yang lebih kurang macam masa training tadi?\n","\n","Cuba main-main dengan setting parameter. Tukar nilai parameter pada fungsi make_classification (n_samples, n_feature, n_informative, n_redundant, dan random_state) dan juga pada fungsi-fungsi lain seperti pada parameter test_size, max_iter, eta0. Kemudian buat kesimpulan hasil daripada penyelidikan anda ini.\n","\n","Oh ya. Jika anda nak cuba menjalankan kod-kod ini, klik sahaja butang ikon \"**Open in Colab**\" yang berada bahagian atas artikel ini."]},{"cell_type":"code","metadata":{"id":"ix7VrqY6BZrK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610549847653,"user_tz":-480,"elapsed":1202,"user":{"displayName":"Azmi Megat","photoUrl":"","userId":"09952198438441952493"}},"outputId":"7f08ee44-9e0f-4f87-e9d8-54a49f1c3ecc"},"source":["# import library sklearn\n","from sklearn.datasets import make_classification\n","from sklearn.linear_model import Perceptron\n","from sklearn.model_selection import train_test_split\n","\n","# Jana data buatan untuk training data & testing data (X->Input y->label). \n","# Pastikan guna nilai random_state yang sama dengan sebelum ini. \n","X, y = make_classification(n_samples=1250, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n","\n","# Asingkan training data & testing data \n","# (testing data = 0.2 x 1250 total data => Train Data = 1000, Test Data = 250)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n","\n","# Bina architecture perceptron algoritma dengan setting terbaik \n","# iteration & learning rate\n","model = Perceptron(max_iter=10,eta0=0.0001)\n","\n","# Train model dengan training data\n","results = model.fit(X_train, y_train)\n","\n","# Paparkan prestasi ketepatan ramalan dengan testing data\n","results.score(X_test,y_test)\n","\n"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.804"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"hXkfcbRdYI5_"},"source":["Ok lah. Sampai di sini sahaja dahulu. InsyaAllah kita akan bertemu kembali. ᕕ( ᐛ )ᕗ"]}]}