{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021-01-19-ml-perceptron.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNH4MOUGO2ncWGhOWknitZd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KSsw1MZdreyW"},"source":["# Pengenalan Kepada Multilayer Perceptron\n","\n","> Perbincangan berkenaan kelemahan perceptron dan bagaimana multilayer perceptron memperbaiki kelemahan tersebut dengan bantuan backpropagation\n","\n","- toc: false \n","- badges: false\n","- comments: true\n","- categories: [deep learning]\n","- image: images/\n","- author: Megat Norulazmi"]},{"cell_type":"markdown","metadata":{"id":"BJQeSjhjswRZ"},"source":["Assalamualaikum dan selamat berjumpa kembali.\n","\n","Pada [artikel yang lepas](https://megatazm.github.io/MyDLBlog/deep%20learning/2021/01/11/perceptron-ml-sklearn.html), kita telah menggunakan perceptron sebagai contoh algoritma di dalam proses machine learning. Seperti yang anda ketahui, algoritma perceptron ini telah di cipta hampir 60 tahun yang lampau. Ia tidak lah cukup berkuasa untuk menyelesai keperluan masa kini yang kompleks dan mencabar. Malahan, kelemahan perceptron yang di temui oleh Marvin Minsky and Seymour Papert pada tahun 1969 telah menyebabkan algoritma berdasarkan pada konsep neural network ini terkubur hampir dua dekad lamanya. \n","\n","Kenapa? <(^,^)>\n","\n","Jika anda membaca artikel saya sebelum ini, ada dinyatakan bahawa perceptron hanya mampu melakukan klasifikasi binari yang datanya adalah ***lineary separable***. \n","\n","Masih ingat? (;¬_¬)\n","\n","Kekangan yang ada pada perceptron ini digambarkan seperti di bawah melalui apa yang dikenali sebagai masalah XOR. Gambarajah di bawah juga menunjukkan perbandingan antara 2 fungsi logik OR dan XOR."]},{"cell_type":"markdown","metadata":{"id":"6fJZoRsb2EJr"},"source":["<br/>\n","<br/>\n","<img src=\"fastcore_imgs/xor-problem.png\" width=\"100%\" height=\"100%\" alt=\"xor problem\">\n","<br/>\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"rqLjvVCI2KlN"},"source":["Di bawah adalah **Truth Table** menunjukkan hubungan input & output yang dihasilkan oleh fungsi logik OR dan XOR (Merujuk pada gambarajah di atas, simbol dot merah = 0 manakala simbol plus biru = 1). "]},{"cell_type":"markdown","metadata":{"id":"hKa9kTlA7Yf-"},"source":["<br/>\n","<br/>\n","<img src=\"fastcore_imgs/xor-or-truthtable.png\" width=\"100%\" height=\"100%\" alt=\"xor-or-truthtable\">\n","<br/>\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"8BO9aj8K8jui"},"source":["Sekiranya kita train perceptron untuk memperolehi model yang berkebolehan seperti fungsi **OR** dan **XOR** ini, kita dapat melihat pada gambarajah di plot kiri (fungsi OR), bahawa perceptron boleh melakukannya melalui satu garisan linear. Namun, pada plot di kanan (fungsi XOR), perceptron tidak mampu melakukanya kerana fungsi XOR adalah dikatakan \"***linearly non-separable***\". Satu-satunya cara untuk memisahkan kedua-dua kelas (biru dan merah) ini adalah dengan menggunakan garisan sempadan bukan linear. Ini jelas menunjukkan bahawa perceptron boleh mempelajari fungsi OR tetapi tidak dapat mempelajari fungsi XOR. \n","\n","Sungguh mengecewakan! ╭╮(︶︿︶)╭╮"]},{"cell_type":"markdown","metadata":{"id":"BKEkB_OYDr_l"},"source":["Secara teorinya kelemahan perceptron itu dapat diselesaikan dengan menambah satu lagi lapisan neuron diatasnya. Ini menghasilkan apa yang disebut sebagai **Multilayer Perceptron** (**MLP**). Gambarajah di bawah menunjukkan bagaimana MLP dapat menyelesaikan masalah XOR. Melalui proses training, gambarajah di bawah menunjukkan nilai weight pada semua sambungan (anak panah) NN yang berwarna hitam adalah 1, manakala yang berwarna merah di tanda dengan nilai seperti di gambarajah. Jika kita menghitung output MLP itu dengan input (0, 0) atau (1, 1), hasil output=0. Manakala jika dengan input (0, 1) atau (1, 0) ia menghasilkan output=1."]},{"cell_type":"markdown","metadata":{"id":"BDvRqme0NFtd"},"source":["<br/>\n","<br/>\n","<img src=\"fastcore_imgs/mlp-solved-xor.png\" width=\"100%\" height=\"100%\" alt=\"mlp-solved-xor\">\n","<br/>\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"JFI-3-pG9a3A"},"source":["Boleh nampak tak? Ok lah saya tunjukkan pengiraannya dengan terperinchi. Sebelum itu, sila rujuk pada penerangan berkenaan perceptron di [artikel saya yang sebelum ini](https://megatazm.github.io/MyDLBlog/deep%20learning/2020/12/29/basic-dl.html). Di bawah adalah rumus yang digunakan untuk mengira output yang keluar di lapisan neuron kedua (hidden layer)."]},{"cell_type":"markdown","metadata":{"id":"Ln_kFrtmn4Gm"},"source":["<br/>\n","\n","![equation](https://latex.codecogs.com/png.download?%5Clarge%20%5Cbegin%7Bmatrix%7D%20%5C%5C%20f_%7Bs_%7Bi%7D%7D%5Cleft%20%28%20z%20%5Cright%20%29%3DWX%20+%20B%20%3D%20%5Cbegin%7Bbmatrix%7D%20w_%7B1%2C1%7D%20%26%20w_%7B1%2C2%7D%20%5C%5C%20w_%7B2%2C1%7D%20%26%20w_%7B2%2C2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D%20x_%7B1%7D%20%5C%5C%20x_%7B2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D%20+%20%5Cbegin%7Bbmatrix%7D%20b_%7B1%7D%20%5C%5C%20b_%7B2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D%20%5C%5C%20%5C%5C%20%3D%5Cbegin%7Bbmatrix%7D%20w_%7B1%2C1%7D%5Ctimes%20x_%7B1%7D%20+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D%20%5C%5C%20w_%7B2%2C1%7D%5Ctimes%20x_%7B1%7D%20+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D+%5Cbegin%7Bbmatrix%7D%20b_%7B1%7D%20%5C%5C%20b_%7B2%7D%20%5C%5C%20%5Cend%7Bbmatrix%7D%20%5Cend%7Bmatrix%7D)\n","<br/>"]},{"cell_type":"markdown","metadata":{"id":"29RXnzr9qS8R"},"source":["Mari kita menghitung nilai output neuron 1 dan neuron 2 di hidden layer terlebih dahulu.\n","\n","* Nilai trained weights:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20w_%7B1%2C1%7D%3D1%2Cw_%7B1%2C2%7D%3D1%2Cw_%7B2%2C1%7D%3D1%2Cw_%7B2%2C2%7D%3D1)\n","\n","* Nilai trained biases weight:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20b_%7B1%7D%3D-1.5%2Cb_%7B2%7D%3D-0.5)\n","\n","* Ketika input:\n","\n","![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D0%2Cx_%7B2%7D%3D0) \n","\n","* Oleh itu output neuron 1 & 2:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20z_%7B1%7D%3Dw_%7B1%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B1%7D%3D%281%29%5Ctimes%280%29+%281%29%5Ctimes%280%29+%28-1.5%29%20%5C%5C%20z_%7B2%7D%3Dw_%7B2%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B2%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B2%7D%3D%281%29%5Ctimes%280%29+%281%29%5Ctimes%280%29+%28-0.5%29%20%5C%5C%20%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B1%7D%7D%28z_%7B1%7D%29%3Df_%7Bs_%7B1%7D%7D%28-1.5%29%3D0%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B2%7D%7D%28z_%7B2%7D%29%3Df_%7Bs_%7B2%7D%7D%28-0.5%29%3D0%5C%5C%20%5Cend%7Bmatrix%7D) \n","\n","\n","* Ketika input: \n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D1%2Cx_%7B2%7D%3D1)\n","\n","* Oleh itu output neuron 1 & 2:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20z_%7B1%7D%3Dw_%7B1%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B1%7D%3D%281%29%5Ctimes%281%29+%281%29%5Ctimes%281%29+%28-1.5%29%20%5C%5C%20z_%7B2%7D%3Dw_%7B2%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B2%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B2%7D%3D%281%29%5Ctimes%281%29+%281%29%5Ctimes%281%29+%28-0.5%29%20%5C%5C%20%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B1%7D%7D%28z_%7B1%7D%29%3Df_%7Bs_%7B1%7D%7D%280.5%29%3D1%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B2%7D%7D%28z_%7B2%7D%29%3Df_%7Bs_%7B2%7D%7D%281.5%29%3D1%5C%5C%20%5Cend%7Bmatrix%7D)\n","\n","* Ketika input: \n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D1%2Cx_%7B2%7D%3D0)\n","\n","* Oleh itu output neuron 1 & 2:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20z_%7B1%7D%3Dw_%7B1%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B1%7D%3D%281%29%5Ctimes%281%29+%281%29%5Ctimes%280%29+%28-1.5%29%20%5C%5C%20z_%7B2%7D%3Dw_%7B2%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B2%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B2%7D%3D%281%29%5Ctimes%281%29+%281%29%5Ctimes%280%29+%28-0.5%29%20%5C%5C%20%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B1%7D%7D%28z_%7B1%7D%29%3Df_%7Bs_%7B1%7D%7D%28-0.5%29%3D0%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B2%7D%7D%28z_%7B2%7D%29%3Df_%7Bs_%7B2%7D%7D%280.5%29%3D1%5C%5C%20%5Cend%7Bmatrix%7D)\n","\n","* Ketika input: \n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D0%2Cx_%7B2%7D%3D1)\n","\n","* Oleh itu output neuron 1 & 2:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20z_%7B1%7D%3Dw_%7B1%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B1%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B1%7D%3D%281%29%5Ctimes%280%29+%281%29%5Ctimes%281%29+%28-1.5%29%20%5C%5C%20z_%7B2%7D%3Dw_%7B2%2C1%7D%20%5Ctimes%20x_%7B1%7D+%20w_%7B2%2C2%7D%5Ctimes%20x_%7B2%7D+b_%7B2%7D%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z_%7B2%7D%3D%281%29%5Ctimes%280%29+%281%29%5Ctimes%281%29+%28-0.5%29%20%5C%5C%20%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B1%7D%7D%28z_%7B1%7D%29%3Df_%7Bs_%7B1%7D%7D%28-0.5%29%3D0%5C%5C%20%5Ctherefore%20%5C%3B%20f_%7Bs_%7B2%7D%7D%28z_%7B2%7D%29%3Df_%7Bs_%7B2%7D%7D%280.5%29%3D1%5C%5C%20%5Cend%7Bmatrix%7D)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9HJl0cOXELBc"},"source":["Di bawah adalah rumus yang digunakan untuk mengira output final yang keluar di lapisan neuron ketiga (output layer)."]},{"cell_type":"markdown","metadata":{"id":"9J5PP-L1Iorl"},"source":["![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20f_%7Bs_%7Boutput%7D%7D%28z%29%3D%5Cbegin%7Bbmatrix%7D%20w_%7B1%2C1%7D%20%26%20w_%7B1%2C2%7D%20%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D%20x_%7B1%7D%5C%5C%20x_%7B2%7D%5C%5C%20%5Cend%7Bbmatrix%7D+%5Cbegin%7Bbmatrix%7D%20b_%7B1%7D%20%5Cend%7Bbmatrix%7D%20%5C%5C%20%5C%5C%20x_%7B1%7D%3D%20f_%7Bs_%7B1%7D%28z%29%7D%5C%5C%20x_%7B2%7D%3D%20f_%7Bs_%7B2%7D%28z%29%7D%5C%5C%20%5Cend%7Bmatrix%7D)"]},{"cell_type":"markdown","metadata":{"id":"tKWxo5TCLfPx"},"source":["Untuk menghitung nilai output neuron di output layer, inputnya adalah nilai output yang dihasilkan oleh 2 neuron dari hidden layer sebelum ini.\n","\n","* Nilai trained weights:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20w_%7B1%2C1%7D%3D-1%2C%20w_%7B2%2C1%7D%3D1)\n","\n","* Nilai trained biases weight:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20b_%7B1%7D%3D-0.5)\n","\n","* ketika input: \n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D0%2Cx_%7B2%7D%3D0)\n","\n","* Oleh itu nilai output:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20%5C%5C%20z%3Dw_%7B1%2C1%7D%5Ctimes%20x_%7B1%7D+w_%7B2%2C1%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%20%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z%3D%28-1%29%5Ctimes%20%280%29+%281%29%5Ctimes%20%280%29+%28-0.5%29%20%5C%5C%20%5C%5C%5Ctherefore%20%5C%3B%20f_%7Bs_%7Boutput%7D%7D%28-0.5%29%3D0%20%5Cend%7Bmatrix%7D)\n","\n","* Ketika input: \n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D1%2Cx_%7B2%7D%3D1)\n","\n","* Oleh itu nilai output:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20%5C%5C%20z%3Dw_%7B1%2C1%7D%5Ctimes%20x_%7B1%7D+w_%7B2%2C1%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%20%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z%3D%28-1%29%5Ctimes%20%281%29+%281%29%5Ctimes%20%281%29+%28-0.5%29%20%5C%5C%20%5C%5C%5Ctherefore%20%5C%3B%20f_%7Bs_%7Boutput%7D%7D%28-0.5%29%3D0%20%5Cend%7Bmatrix%7D)\n","\n","* Ketika input: \n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20x_%7B1%7D%3D0%2Cx_%7B2%7D%3D1)\n","\n","* Oleh itu nilai output:\n","\n"," ![equation](https://latex.codecogs.com/png.download?%5Cdpi%7B120%7D%20%5Clarge%20%5Cbegin%7Bmatrix%7D%20%5C%5C%20z%3Dw_%7B1%2C1%7D%5Ctimes%20x_%7B1%7D+w_%7B2%2C1%7D%5Ctimes%20x_%7B2%7D+b_%7B1%7D%20%5C%5C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20z%3D%28-1%29%5Ctimes%20%280%29+%281%29%5Ctimes%20%281%29+%28-0.5%29%20%5C%5C%20%5C%5C%5Ctherefore%20%5C%3B%20f_%7Bs_%7Boutput%7D%7D%280.5%29%3D1%20%5Cend%7Bmatrix%7D)"]},{"cell_type":"markdown","metadata":{"id":"rZ8I7D70ghid"},"source":["Dengan pengiraan di atas, maka jelas lah multilayer perceptron boleh menyelesaikan masalah XOR ini. Tetapi mengapa algoritma neural network ini terkubur begitu lama sekali dan bagaimana ia akhirnya menjadi tumpuan para penyelidik semula. Cerita seterusnya akan saya bincangkan di artikel yang seterusnya, \n","\n","InsyaAllah!"]}]}