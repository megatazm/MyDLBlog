{
  
    
        "post0": {
            "title": "Multilayer Perceptron dan Backpropagation & Gradient Decent",
            "content": "Assalamualaikum dan selamat berjumpa kembali. . Pada artikel yang lepas, saya telah memberi penerangan yang ringkas berkenaan kelemahan perceptron merujuk kepada masalah XOR dan bagaimana multilayer perceptron dapat menyelesaikannya. Saya juga ada melontarkan persoalan, &quot;Mengapa algoritma yang berasaskan pada neural network ini terkubur selama hampir dua dekad ?&quot;, walaupun permasalahan XOR itu boleh diselesaikan oleh multilayer perceptron. . Permasalahan besar muncul apabila multilayer perceptron (MLP) itu ingin digunakan untuk di latih dengan data non-linearly separable yang sebenar, bukan setakat data yang sangat asas seperti masalah XOR itu. Mungkin anda terfikir, (ー_ーゞ . &quot;Jika datanya kompleks seperti itu maka tambahkanlah dengan lebih banyak neuron dan lapisan hidden layer&quot; . Bijak! memang tepat sekali jangkaan anda, tetapi sanggupkah anda menunggu proses training model itu selama beribu-ribu tahun? Tak berbaloi kan? Oleh kerana kegagalan para penyelidik ketika itu mencari kaedah melatih MLP dalam satu jangka masa yang munasabah lah yang menjadi punca utama mengapa neural network terkubur sekian lama. . Akhirnya pada tahun 1986, David Rumelhart, Geoffrey Hinton, and Ronald Williams telah memecah kebuntuan dengan memperkenalkan algoritma backpropagation yang berkait rapat dengan algoritma Gradient Decent (ini pernah di sebut di artikel pertama saya). Mungkin timbul beberapa persoalan di minda anda, ʕ ʘ̅͜ʘ̅ ʔ . &quot;Kenapa namanya Backpropagation, takda nama lain ker? Apa kaitannya pulak dengan Gradient Decent? Benda yang sama jer kot nama sajer yang lain&quot; . Di artikel yang sebelum ini saya ada menunjukkan pengiraan multilayer perceptron menyelesaikan masalah XOR bermula dari input layer, hidden layer, dan output layer kan? Ini adalah dinamakan neural network dengan proses feedforward sebab ia hanya melibatkan process yang maju kehadapan sahaja. Dengan adanya algoritma backpropagation, neural network ini berfungsi dengan dua arah iaitu ke depan dan ke belakang berulang kali. . &quot;Melatih model dengan algoritma Gradient Decent (GD) menggunakan Backpropagation (BP) sebagai teknik pengkomputeran gradien ataupun kecerunan&quot; . Frasa di atas mengambarkan hubungan antara kedua-dua algoritma tersebut iaitu GD adalah algoritma bagi mencapai kecerunan K=0 dalam masa T, manakala BP adalah algoritma yang penting untuk menjalankan proses pengiraan kecerunan tersebut dari setiap lapisan, dari depan hinggalah ke lapisan belakang neuron dengan efisien. . Kecerunan apa? mungkin ada yang tertanya-tanya. Ia adalah kecerunan ataupun slop yang terhasil oleh perubahan error terhadap perubahan parameter weight (k=de/dw). Dengan kata lain, berapakah nilai perubahan pada error jika nilai parameter weight berubah pada sesuatu nilai tertentu. Jika kecerunannya adalah 0 (zero) ataupun mendatar ia di anggap sebagai di mana nilai error e yang paling minimum telah di temui (pada satu titik nilai parameter weight w). . Secara analoginya, ia juga boleh di anggap seperti anda sedang mencuba turun dari atas bukit ke bawah kaki bukit dalam keadaan gelap. Anda terus menuruni cerun selagi anda merasakan kaki dan kepala menunduk ke bawah. Sebaliknya, anda akan berpatah ke belakang apabila anda merasakan kaki dan kepala anda mendongak ke atas. Anda terus-menerus mengulangi proses turun dan naik cerun itu sehinggalah anda yakin yang anda sudah berada di kawasan tanah rata. Proses GD ini boleh digambarkan seperti di bawah (Y adalah fungsi error atau cost manakala X adalah parameter weight). . . Anda masih ingat lagi pada artikel yang lepas, Pengenalan Kepada Perceptron?, saya ada menyatakan yang kita perlu &quot;tune&quot; kelajuan training model melalui learning rate. Supaya ia tidak terlalu laju dan tidak lah pula terlalu perlahan. Saya juga ada memberi analogi, &quot;Seperti memasukkan benang ke dalam lubang di jarum&quot; kan? Gambarajah di bawah memberikan gambaran yang lebih jelas mengapa kita perlu melakukan hyperparameter tuning pada learning rate setiap kali melakukan proses training model. . . Gambarajah di atas menunjukkan nilai setting learning rate yang terlalu kecil. Walaupun ini memberi kebarangkalian yang lebih kepada algoritma GD untuk sampai ke titik paling rendah, tetapi ianya akan mengambil masa yang lama. Manakala gambarajah di bawah pula menunjukkan reaksi algoritma GD yang terpantul-pantul di sekitar cerunan tanpa berjaya sampai ke titik paling rendah apabila setting learning ratenya terlampau besar. . . Namun, tidak semestinya bentuk cerun yang dihasilkan oleh fungsi error ataupun cost ini cantik bentuknya seperti di atas. Kemungkinan besar bentuk cerunannya adalah seperti gambarajah di bawah, terdapat lubang, lereng, dataran tinggi, dan segala macam permukaan yang tidak sekata, sehingga sukar untuk mencapai titik yang paling minimum. . . Seperti contoh, sekiranya algoritma GD bermula dengan nilai permulaan parameter weight di sebelah kiri (seperti di gambarajah), maka ia akan tersangkut di titik minimum yang di panggil local minimum, yang sebenarnya bukanlah titik paling minimum ( global minimum ialah titik minimum yang sepatutnya di capai ). Sebaliknya, jika nilai permulaan parameter weight bermula di sebelah kanan, ia akan memakan masa yang sangat lama untuk menyeberangi kawasan dataran tinggi. Jika anda berhenti iteration training terlalu awal, anda tidak akan sempat mencapai ke tahap global minimum itu. Untuk pengetahuan anda, ada banyak jenis algoritma optimization untuk algoritma GD ini yang boleh digunakan mengikut kesesuaian fungsi cost dan dataset, seperti RMSprop, Adam, AdaMax, AdaGrad, Momentum dan banyak lagi. . Berikut adalah penerangan yang lebih tersusun berkenaan proses feedforward dan backpropogation. . Proses ini berlaku pada setiap batch atau kumpulan kecil data. Misalnya, jika setiap batch adalah terdiri daripada 20 rekod data (1 batch = 20 rekod) dan jumlah kesemua rekod data adalah 1000 (1 epoch = 1000 rekod), maka proses ini berlaku sebanyak 1000/20 = 50 batch pada setiap epoch. | Feedforward bermula dari input layer, dan ke hidden layer pertama dan seterusnya. Feedforward mengira output di semua neuron pada setiap lapisan berdasarkan pada setiap batch data tersebut sehinggalah ke lapisan terakhir iaitu output layer, di mana nilai ramalan dihasilkan. Semua hasil pengiraan pada batch di setiap lapisan neuron tersebut disimpan kerana ia diperlukan untuk kegunaan proses backpropagation (1 batch = 1 iteration = 1 Feedforward + 1 Backpropogation). | Seterusnya, algoritma mengukur error di output layer (ia menggunakan fungsi error atau cost yang membandingkan output yang telah dilabelkan dan output ramalan) dan nilai error ini akan digunakan oleh backpropagation. | Kemudian ia menghitung berapa besarkah setiap sambungan weight output menyumbang kepada error tersebut (mengukur kecerunan k=de/dw). Ini dilakukan secara analitik dengan menggunakan &quot;chain-rule&quot; (salah satu ilmu asas matematik kalkulus dalam silibus SPM), yang menjadikan proses pengiraan ini cepat dan tepat. | Algoritma kemudian mengukur berapa banyak sumbangan error yang datang dari setiap sambungan weight di setiap lapisan neural network bergerak ke arah belakang sehinggalah ke lapisan input layer dengan menggunakan teknik chain-rule itu. Seperti yang dijelaskan sebelumnya, backpropagation ini mengukur kecerunan error terhadapan sambungan weight dengan efisen pada semua sambungan weight dalam setiap lapisan neural network dengan menyebarkan nilai kecerunan tersebut ke belakang. | Akhirnya, algoritma Gradient Descent beraksi dengan mengubah semua nilai weight di dalam setiap lapisan neural network berdasarkan pada nilai kecerunan atau gradien error yang dikira sebelum ini. Proses feedforward &amp; backpropagation ini berlaku berulang-ulang kali berdasarkan pada jumlah epoch yang anda tetapkan. | . Bagi membolehkan algoritma ini dapat berfungsi seperti yang diharapkan, fungsi activation step pada MLP itu perlu digantikan fungsi yang lain. Ini penting kerana fungsi step hanya mempunyai garisan menegak dan mendatar, jadi tidak ada kecerunan yang dihasilkan untuk kegunaan algoritma gradient descent. Oleh itu kita memerlukan fungsi activation yang &quot;continuous &amp; differentiable&quot; iaitu fungsi yang boleh menghasilkan gradien atau kecerunan disepanjang garisan melalui perubahan error terhadap perubahan parameter weight. Ini membolehkan algoritma gradient descent bergerak menuju ke arah titik minimum pada setiap iteration. Berikut adalah beberapa fungsi activation yang biasa digunakan, . Fungsi sigmoid, σ (z) = 1 / (1 + exp (–z) ). | . Fungsi tangen hiperbolik: tanh (z) = 2σ (2z) - 1 | . Fungsi Rectified Linear Unit, ReLU (z) = max (0, z) | . Gambarajah di bawah menunjukkan fungsi activation dan derivatifnya (di sebelah kanan). Kita akan bincangkan berkenaan fungsi-fungsi ini di artikel yang akan datang. . . Oh ya, anda masih ingat satu lagi tujuan penting activation function yang pernah saya nyatakan sebelum ini? Ya! untuk membolehkan kita membina model non-linear bagi menyelesaikan permasalahan yang kompleks, kita menggunakan activation function seperti ini untuk menukarnya dari dunia linear ke dunia non-linear. . Kenapa? sebab jikalau ianya masih lagi dalam bentuk linear, maka takda maknanya pun kalau kita tambah hidden layer tu berlapis-lapis bagi tujuan untuk membina suatu model yang kompleks. Sebagai contoh, jika . f (x) = 2x + 3, dan g (x) = 5x - 1 . Kemudian kita sambungkan kedua-dua fungsi linear itu (menjadi dua lapisan network), ia sebenarnya hanya menghasilkan satu lapisan fungsi linear sahaja. . f (g (x)) = 2 (5x - 1) + 3 = 10x + 1 . Oleh itu, tak kiralah berapa ribu hidden layer pun yang anda tambah, akhirnya ia cuma menjadi satu fungsi linear yang berbeza nilai kecerunan dan ketinggiannya. . Ok lah, cukup di sini sahaja buat masa ini. Di artikel yang akan datang, insyaAllah saya akan tunjukkan satu contoh implementasi MLP Classification menggunakan Keras. ᕕ( ᐛ )ᕗ . .",
            "url": "https://megatazm.github.io/MyDLBlog/deep%20learning/2021/01/31/mlp-backpropagation.html",
            "relUrl": "/deep%20learning/2021/01/31/mlp-backpropagation.html",
            "date": " • Jan 31, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Pengenalan Kepada Multilayer Perceptron",
            "content": "Assalamualaikum dan selamat berjumpa kembali. . Pada artikel yang lepas, kita telah menggunakan perceptron sebagai contoh algoritma di dalam proses machine learning. Seperti yang anda ketahui, algoritma perceptron ini telah di cipta hampir 60 tahun yang lampau. Ia tidak lah cukup berkuasa untuk menyelesai keperluan masa kini yang kompleks dan mencabar. Malahan, kelemahan perceptron yang di temui oleh Marvin Minsky and Seymour Papert pada tahun 1969 telah menyebabkan algoritma berdasarkan pada konsep neural network ini terkubur hampir dua dekad lamanya. . Kenapa? &lt;(^,^)&gt; . Jika anda membaca artikel saya sebelum ini, ada dinyatakan bahawa perceptron hanya mampu melakukan klasifikasi binari yang datanya adalah lineary separable. . Masih ingat? (;¬_¬) . Kekangan yang ada pada perceptron ini digambarkan seperti di bawah melalui apa yang dikenali sebagai masalah XOR. Gambarajah di bawah juga menunjukkan perbandingan antara 2 fungsi logik OR dan XOR. . . Di bawah adalah Truth Table menunjukkan hubungan input &amp; output yang dihasilkan oleh fungsi logik OR dan XOR (Merujuk pada gambarajah di atas, simbol dot merah = 0 manakala simbol plus biru = 1). . . Sekiranya kita train perceptron untuk memperolehi model yang berkebolehan seperti fungsi OR dan XOR ini, kita dapat melihat pada gambarajah di plot kiri (fungsi OR), bahawa perceptron boleh melakukannya melalui satu garisan linear. Namun, pada plot di kanan (fungsi XOR), perceptron tidak mampu melakukanya kerana fungsi XOR adalah dikatakan &quot;linearly non-separable&quot;. Satu-satunya cara untuk memisahkan kedua-dua kelas (biru dan merah) ini adalah dengan menggunakan garisan sempadan bukan linear. Ini jelas menunjukkan bahawa perceptron boleh mempelajari fungsi OR tetapi tidak dapat mempelajari fungsi XOR. . Sungguh mengecewakan! ╭╮(︶︿︶)╭╮ . Secara teorinya kelemahan perceptron itu dapat diselesaikan dengan menambah satu lagi lapisan neuron diatasnya. Ini menghasilkan apa yang disebut sebagai Multilayer Perceptron (MLP). Gambarajah di bawah menunjukkan bagaimana MLP dapat menyelesaikan masalah XOR. Melalui proses training, gambarajah di bawah menunjukkan nilai weight pada semua sambungan (anak panah) NN yang berwarna hitam adalah 1, manakala yang berwarna merah di tanda dengan nilai seperti di gambarajah. Jika kita menghitung output MLP itu dengan input (0, 0) atau (1, 1), hasil output=0. Manakala jika dengan input (0, 1) atau (1, 0) ia menghasilkan output=1. . . Boleh nampak tak? Ok lah saya tunjukkan pengiraannya dengan terperinchi. Sebelum itu, sila rujuk pada penerangan berkenaan perceptron di artikel saya yang sebelum ini. Di bawah adalah rumus yang digunakan untuk mengira output yang keluar di lapisan neuron kedua (hidden layer). . . . Mari kita menghitung nilai output neuron 1 dan neuron 2 di hidden layer terlebih dahulu. . Nilai trained weights: . . | Nilai trained biases weight: . . | Ketika input: . | . . Oleh itu output neuron 1 &amp; 2: . . | . Ketika input: . . | Oleh itu output neuron 1 &amp; 2: . . | Ketika input: . . | Oleh itu output neuron 1 &amp; 2: . . | Ketika input: . . | Oleh itu output neuron 1 &amp; 2: . . | . Di bawah adalah rumus yang digunakan untuk mengira output final yang keluar di lapisan neuron ketiga (output layer). . . Untuk menghitung nilai output neuron di output layer, inputnya adalah nilai output yang dihasilkan oleh 2 neuron dari hidden layer sebelum ini. . Nilai trained weights: . . | Nilai trained biases weight: . . | ketika input: . . | Oleh itu nilai output: . . | Ketika input: . . | Oleh itu nilai output: . . | Ketika input: . . | Oleh itu nilai output: . . | . Dengan pengiraan di atas, maka jelas lah multilayer perceptron boleh menyelesaikan masalah XOR ini. Tetapi mengapa algoritma neural network ini terkubur begitu lama sekali dan bagaimana ia akhirnya menjadi tumpuan para penyelidik semula. Cerita seterusnya akan saya bincangkan di artikel yang seterusnya, . InsyaAllah! .",
            "url": "https://megatazm.github.io/MyDLBlog/deep%20learning/2021/01/19/ml-perceptron.html",
            "relUrl": "/deep%20learning/2021/01/19/ml-perceptron.html",
            "date": " • Jan 19, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Mengaplikasikan Perceptron Dengan Scikit-learn Library",
            "content": "Assalamualaikum dan selamat berjumpa kembali. . Seperti yang telah saya nukilkan pada artikel yang lepas, saya telah menerangkan dengan serba ringkas berkenaan mekanisma perceptron dan menunjukkan contoh penggunaan mudah perceptron menggunakan sklearn library (ataupun scikit-learn). Di artikel ini, saya akan menulis penggunaan perceptron dengan aturan proses machine learning yang lebih lengkap daripada sebelum ini. . Untuk kali ini, saya masih menggunakan sklearn library. Mungkin ada yang berkata-kata, . &quot;Asyik sebut-sebut keras, tensorflow dan pytorch jer sebelum ini, tapi tak pakai-pakai pun&quot;. . InsyaAllah saya cuba perkenalkan asas penggunaanya di artikel yang seterusnya ya. . Berikut adalah pecahan proses yang kita akan lakukan pada kali ini:- . Import library sklearn yang diperlukan | Menghasilkan data buatan menggunakan library sklearn make_classification | Bina perceptron menggunakan library sklearn Perceptron | Melakukan model validation dengan stratified k-fold cross validation menggunakan library sklearn RepeatedStratifiedKFold | Train model perceptron menggunakan data buatan tersebut | Melakukan hyperparameter tuning untuk learning rate dan kekerapan iteration melalui sklearn library GridSearchCV | Memaparkan prestasi validation model tersebut berdasarkan pada kombinasi beberapa nilai learning rate dan iteration yang berbeza. | Menguji prestasi model menggunakan test data dengan kombinasi learning rate dan kekerapan iteration pilihan yang terbaik, kemudian memaparkan prestasi ketepatannya. | Pertama sekali, import library yang bakal kita gunakan, . make_classification - Fungsi untuk menghasilkan data buatan | GridSearchCV - Fungsi untuk melakukan hyperparameter tuning | RepeatedStratifiedKfold - Fungsi untuk menjalankan stratified k-fold cross validation yang boleh ditentukan kekerapan ulangan. | Perceptron - Fungsi untuk membina architecture algoritma perceptron | . # import sklearn library yang akan digunakan from sklearn.datasets import make_classification from sklearn.model_selection import GridSearchCV from sklearn.model_selection import RepeatedStratifiedKFold from sklearn.linear_model import Perceptron . Tujuan kita menggunakan fungsi make_classification ini adalah menghasilkan data yang sesuai untuk perceptron melakukan klasifikasi binari. Ini kerana perceptron hanya mampu melakukan klasifikasi pada data yang &quot;linearly separable&quot;, iaitu data yang mudah diasingkan kepada dua kelas dengan menggunakan satu garisan linear. Fungsi make_classification ini juga boleh digunakan untuk menghasilkan pelbagai jenis data klasifikasi yang kompleks. Ia sangat berguna untuk menguji prestasi dan melakukan perbandingan di antara pelbagai jenis algoritma klasifikasi yang lama dan baharu. Penerangan berkenaan penggunaan fungsi ini boleh di rujuk di sini. Bagi tujuan contoh ini, kita hanya akan menggunakan parameternya yang berikut, . n_samples - Untuk menentukan jumlah instance atau rekod. Di sini saya setkan dengan nilai n_samples=1000. | n_feature - Untuk menentukan jumlah input fitur. Di sini saya setkan n_feature=10 | n_informative - Untuk menentukan samada input fitur yang telah ditetapkan jumlahnya sebentar tadi adalah berinformatif. Nilai tetapannya mestilah tidak melebihi dengan nilai n_feature. Di sini saya setkan nilai n_informative = 10 | n_redundant - Oleh kerana kita telah menetapkan kesemua 10 feature kita adalah informatif maka di sini n_redundant = 0. Jika contohnya kita setkan n_redundant = 5, maka mestilah nilai n_informative=5 kerana total fitur adalah 10 (jika n_informative=4, n_redundant = 5, maka fitur selebihnya secara default disetkan sebagai noise). Lagi tinggi fitur informatif maka lagi mudahlah model perceptron itu di latih dan memperolehi ketepatan ramalan yang tinggi. | random_state - Jujukan data instance atau rekod yang akan dihasilkan nanti adalah random. Namun, untuk memastikan data random ini adalah &quot;reproducible&quot;, maksudnya untuk memastikan data ini sentiasa sama jika kita menghasilkannya berulang kali. Oleh itu, anda perlu setkan nilai integer yang sama pada random_state itu. Seperti contoh, di sini saya setkan random_state = 1. | . # Menghasilkan dataset buatan. Cuba awak run kod ini berkali-kali. Hasilnya # tetap sama kan? Cuba tukar nilai random_state=2, kemudian run. Sama juga ker? X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1) #uncomment ini untuk lihat data yang terhasil #print (X, y) . Untuk membina architecture NN perceptron, kita menggunakan fungsi perceptron dari library sklearn (tak perlu bina &quot;from scratch&quot;). Fungsi ini juga ada banyak setting parameternya. Anda boleh rujuk di sini. Tapi, untuk contoh ini kita gunakan setting default sahaja. Setting parameter learning rate dan iteration pada fungsi perceptron ini akan kita lakukan melalui fungsi GridSearchCV. Hasilnya di simpan di dalam variable model. . # Bina NN default perceptron model = Perceptron() . Sebelum menjalankan proses training dengan stratified k-fold cross validation (Saya ada berikan penerangan berkenaan proses ini di artikel yang pertama), kita perlu tetapkan nilai parameter pada fungsi RepeatedStratifiedKFold terlebih dahulu. Fungsi ini hanya ada 3 parameter sahaja yang perlu ditentukan nilainya. Penerangan lengkapnya ada di sini. Setting parameternya adalah seperti berikut, . n_splits - Adalah untuk menentukan nilai k. Dalam contoh ini, saya setkan k=10 (n_splits=10), bermaksud data ini akan diasingkan sebanyak 10 bahagian (9 data training dan 1 data testing) | n_repeats - Menetapkan kekerapan proses 10-fold cross validation yang ingin di ulangi. Saya setkan n_repeats=3. | random_state - Saya rasa anda boleh agak tujuan parameter ini kan? Bagus! anda memang bijak. | . Hasil tetapan ini kemudiannya di simpan di variable cv. . # tetapkan setting model validation stratified k-fold cross validation cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) . Di sini kita tetapkan konfigurasi hyperparameter tuning yang ingin dijalankan ke dalam variable grid. Di contoh ini, saya hanya tetapkan parameter &#39;max_iter&#39; untuk iteration dan &#39;eta0&#39; untuk learning rate sahaja, setiap satunya dengan 5 nilai-nilai yang berbeza (parameter &#39;max_iter dan &#39;eta0&#39; ini adalah berdasarkan pada tetapan parameter yang di sokong oleh fungsi perceptron( )). Akhir sekali, di fungsi GridSearchCV, masukkan variable model, grid dan cv yang telah kita konfigurasikan tadi ke tempat yang betul dengan tetapan parameter yang lain seperti scoring=&#39;accuracy&#39; untuk memaparkan ketepatan prestasinya dan parameter n_jobs=-1 supaya pemprosesan ini menggunakan kesemua cpu yang ada di komputer. Hasil tetapan fungsi GridSearchCV ini kemudiannya di simpan ke dalam variable search. . # set grid nilai-nilai pada parameter dengan dictionary data structure grid = dict() grid={&#39;max_iter&#39;:(1, 10, 100, 1000, 10000),&#39;eta0&#39;:(0.0001, 0.001, 0.01, 0.1, 1.0)} # Jalankan training melalui proses cross validation setting cv # dan melalui kombinasi 5 nilai pada max_iter dan eta0 tersebut search = GridSearchCV(model, grid, scoring=&#39;accuracy&#39;, cv=cv, n_jobs=-1) . Melalui variable search, train model klasifikasi perceptron ini menggunakan data buatan yang telah di jana. Hasil dapatan dari proses training ini akan di simpan di dalam variable results. . # train model dengan cross validation, beserta kombinasi pelbagai # nilai learning rate dan iteration dan pulangkan hasil dapatan # di variable results results = search.fit(X, y) . Melalui variable results tadi, dengan mudahnya kita boleh mempamirkan maklumat, . Purata prestasi ketepatan ramalan terbaik | Kombinasi learning rate &amp; iteration terbaik | Senarai lengkap purata prestasi ketepatan ramalan dengan setiap kombinasi learning &amp; iteration. | . Merujuk pada maklumat yang dipaparkan di bawah, ketepatan tertinggi adalah 85.7% manakala kombinasi parameter learning rate &amp; iteration terbaik yang dicadangkan adalah eta0=0.0001 (lagi besar learning rate lagi cepat proses training selesai) &amp; max_iter=10 (lagi kurang iteration, lagi cepat proses training selesai). . # summarize print(&#39;Mean Accuracy: %.3f&#39; % results.best_score_) print(&#39;Config: %s&#39; % results.best_params_) # summarize all means = results.cv_results_[&#39;mean_test_score&#39;] params = results.cv_results_[&#39;params&#39;] for mean, param in zip(means, params): print(&quot;&gt;%.3f with: %r&quot; % (mean, param)) . Mean Accuracy: 0.857 Config: {&#39;eta0&#39;: 0.0001, &#39;max_iter&#39;: 10} &gt;0.850 with: {&#39;eta0&#39;: 0.0001, &#39;max_iter&#39;: 1} &gt;0.857 with: {&#39;eta0&#39;: 0.0001, &#39;max_iter&#39;: 10} &gt;0.857 with: {&#39;eta0&#39;: 0.0001, &#39;max_iter&#39;: 100} &gt;0.857 with: {&#39;eta0&#39;: 0.0001, &#39;max_iter&#39;: 1000} &gt;0.857 with: {&#39;eta0&#39;: 0.0001, &#39;max_iter&#39;: 10000} &gt;0.850 with: {&#39;eta0&#39;: 0.001, &#39;max_iter&#39;: 1} &gt;0.857 with: {&#39;eta0&#39;: 0.001, &#39;max_iter&#39;: 10} &gt;0.857 with: {&#39;eta0&#39;: 0.001, &#39;max_iter&#39;: 100} &gt;0.857 with: {&#39;eta0&#39;: 0.001, &#39;max_iter&#39;: 1000} &gt;0.857 with: {&#39;eta0&#39;: 0.001, &#39;max_iter&#39;: 10000} &gt;0.850 with: {&#39;eta0&#39;: 0.01, &#39;max_iter&#39;: 1} &gt;0.846 with: {&#39;eta0&#39;: 0.01, &#39;max_iter&#39;: 10} &gt;0.853 with: {&#39;eta0&#39;: 0.01, &#39;max_iter&#39;: 100} &gt;0.853 with: {&#39;eta0&#39;: 0.01, &#39;max_iter&#39;: 1000} &gt;0.853 with: {&#39;eta0&#39;: 0.01, &#39;max_iter&#39;: 10000} &gt;0.850 with: {&#39;eta0&#39;: 0.1, &#39;max_iter&#39;: 1} &gt;0.836 with: {&#39;eta0&#39;: 0.1, &#39;max_iter&#39;: 10} &gt;0.847 with: {&#39;eta0&#39;: 0.1, &#39;max_iter&#39;: 100} &gt;0.847 with: {&#39;eta0&#39;: 0.1, &#39;max_iter&#39;: 1000} &gt;0.847 with: {&#39;eta0&#39;: 0.1, &#39;max_iter&#39;: 10000} &gt;0.850 with: {&#39;eta0&#39;: 1.0, &#39;max_iter&#39;: 1} &gt;0.836 with: {&#39;eta0&#39;: 1.0, &#39;max_iter&#39;: 10} &gt;0.847 with: {&#39;eta0&#39;: 1.0, &#39;max_iter&#39;: 100} &gt;0.847 with: {&#39;eta0&#39;: 1.0, &#39;max_iter&#39;: 1000} &gt;0.847 with: {&#39;eta0&#39;: 1.0, &#39;max_iter&#39;: 10000} . Ok. Mari kita cuba train model ini semula dengan kombinasi learning rate &amp; iteration yang terbaik, kemudian mengujinya dengan test data. Bagaimana? boleh dapat prestasi yang lebih kurang macam masa training tadi? . Cuba main-main dengan setting parameter. Tukar nilai parameter pada fungsi make_classification (n_samples, n_feature, n_informative, n_redundant, dan random_state) dan juga pada fungsi-fungsi lain seperti pada parameter test_size, max_iter, eta0. Kemudian buat kesimpulan hasil daripada penyelidikan anda ini. . Oh ya. Jika anda nak cuba menjalankan kod-kod ini, klik sahaja butang ikon &quot;Open in Colab&quot; yang berada bahagian atas artikel ini. . # import library sklearn from sklearn.datasets import make_classification from sklearn.linear_model import Perceptron from sklearn.model_selection import train_test_split # Jana data buatan untuk training data &amp; testing data (X-&gt;Input y-&gt;label). # Pastikan guna nilai random_state yang sama dengan sebelum ini. X, y = make_classification(n_samples=1250, n_features=10, n_informative=10, n_redundant=0, random_state=1) # Asingkan training data &amp; testing data # (testing data = 0.2 x 1250 total data =&gt; Train Data = 1000, Test Data = 250) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) # Bina architecture perceptron algoritma dengan setting terbaik # iteration &amp; learning rate model = Perceptron(max_iter=10,eta0=0.0001) # Train model dengan training data results = model.fit(X_train, y_train) # Paparkan prestasi ketepatan ramalan dengan testing data results.score(X_test,y_test) . 0.804 . Ok lah. Sampai di sini sahaja dahulu. InsyaAllah kita akan bertemu kembali. ᕕ( ᐛ )ᕗ .",
            "url": "https://megatazm.github.io/MyDLBlog/deep%20learning/2021/01/11/perceptron-ml-sklearn.html",
            "relUrl": "/deep%20learning/2021/01/11/perceptron-ml-sklearn.html",
            "date": " • Jan 11, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Pengenalan Kepada Perceptron",
            "content": "Assalamualaikum. Selamat berjumpa kembali. . Seperti yang saya maklumkan pada artikel yang lepas, saya telah berjanji untuk cuba memberikan sedikit penerangan asas berkenaan teori DL ini. Kalau nak diikutkan, jika kita menggunakan library Tensorflow atau Pytorch nanti, kesemua yang kita bincang ini akan diabstrakkan implementasinya. . Dengan kata lain, &quot;Tak payah tau pun, pakai jer&quot;. . Tapi saya rasa anda perlu tahu juga konsep asasnya terlebih dahulu, sebab ini akan membantu anda untuk majukan ke tahap penggunaan DL yang lebih kompleks. Lagipun, tak kanlah nak pakai jer library Tensorflow atau Pytorch membuta tuli kan? . Perceptron . Perceptron adalah salah satu architecture ANN yang paling asas, dicipta pada tahun 1957 oleh Frank Rosenblatt. Ia berdasarkan pada konsep neuron (lihat gambar di bawah) yang disebut Treshold Logic Unit (TLU), ataupun Logic Treshold Unit (LTU). Nilai input dan outputnya adalah nombor (bukan nilai on/off binari), dan setiap sambungan di antara input nod dan output nod itu diberikan nilai pemberat atau weight. Secara analoginya, lagi besar weight maka lagi tebal lah wayar sambungannya (Lagi besar pengaruhnya). . . TLU menghitung jumlah weight berserta dengan inputnya seperti yang ditunjukkan oleh rumus di bawah, . kemudian hasil z itu diaplikasikan kepada fungsi step(z) untuk menghasilkan nilai output yang baharu, . Menyingkap kembali pada artikel yang sebelum ini, ia masih menggunakan rumus yang sama iaitu y = ax + b tanpa pembolehubah b. Merujuk pada ini, ada sedikit perbezaan iaitu nilai output adalah hasil dari 3 input fitur x dengan nilai pengaruh weight w (dahulunya a) pada setiap fitur tersebut. Perbezaan yang paling utama adalah peranan Step Function sebagai &quot;Activation Function&quot;. Idea activation function ini penting untuk membolehkan kita membina model yang non-linear (perceptron adalah algoritma linear untuk klasifikasi binari kerana nilai aktivasinya adalah 1 atau 0). Kenapa kita perlukan model non-linear? Cuba ingat balik fakta dari artikel yang lepas, garisan linear hanya mampu menghasilkan suatu model yang underfit atau high bias. Ini bukan suatu model yang kita inginkan untuk menyelesaikan masalah yang kompleks. . Mungkin ada yang tertanya-tanya kenapa ada huruf superscript T di atas huruf x itu? . . Ini kerana ia melibatkan pengiraan menggunakan Matrix Multiplication. Janganlah rasa takut bila dengar terma matrix ini. Anda hanya perlu tahu asas berkenaan ilmu matematik matrix yang di pelajari di sekolah menengah. Lagipun semua pengiraan ini nanti akan dilakukan oleh library Tensorflow atau Pytorch. . Ok. Huruf T adalah merujuk kepada proses matrix yang di panggil Transpose. Ia diperlukan untuk membetulkan bentuk dimensi matrix x bagi membolehkan ia multiply dengan matrix w. Contoh, jika bentuk dimensi matrix x dan w adalah (3,1), operasi matrix dimensi x(3,1) x w(3,1) itu perlu ditukarkan ke bentuk x(1,3) x w(3,1) terlebih dahulu dengan melakukan proses transpose pada matrix x. . Jika anda sudah lupa berkenaan operasi asas matrix, bolehlah rujuk kembali pada buku SPM anda. InsyaAllah, sayang anda pada cikgu matematik akan bertambah. . Ok. Bagaimana pula dengan Step Function? . Cuba lihat notasi matematik di bawah. Ia merujuk kepada dua jenis fungsi Step bernama Heaviside dan Sign. Dulu saya cukup fobia bila melihat notasi matematik dengan simbol macam cacing ni. Tapi sebenarnya jika anda cuba amati notasi tersebut ia sebenarnya adalah merupakan satu &quot;bahasa&quot; simbolik. Jika anda hafal maksud simbol-simbolnya maka mudahlah memahami maksudnya. . Fungsi heaviside akan mengeluarkan nilai 0 jika nilai z adalah lebih kecil daripada 0. Sebaliknya, ia mengeluarkan nilai 1 jika nilai z adalah sama atau lebih besar daripada 0. . . . . Manakala fungsi Sign pula akan mengeluarkan nilai -1 jika nilai z adalah lebih kecil daripada 0. Ia juga mengeluarkan nilai 0 jika nilai z adalah 0, dan mengeluarkan nilai +1 jika nilai z adalah lebih besar daripada 0. . . . Untuk memberi gambaran jelas pada yang &quot;visual learner&quot;, cuba lakarkan graf pada paksi z -&gt; X dan sgn(z) -&gt; Y. Saya serahkan pada anda untuk melakarkannya. . Architecture TLU tunggal ini boleh digunakan untuk klasifikasi binari yang mudah seperti Hujan (1) atau Tidak (0). Ia menghitung kombinasi linear dari 3 input x (dengan nilai weight masing-masing), dan jika hasil z melebihi nilai treshold (z &gt;= 0) seperti yang ditetapkan oleh contohnya fungsi heaviside, ia akan menghasilkan prediksi kelas positif (1). Jika sebaliknya, ia menghasilkan prediksi kelas negatif (0). Melatih TLU dalam kes ini bermaksud mencari nilai yang optimum untuk weight w1, w2, dan w3 itu. . Perceptron hanya terdiri daripada satu lapisan TLU, dengan setiap TLU disambungkan ke semua input. Apabila semua neuron dalam lapisan disambungkan ke setiap neuron pada lapisan sebelumnya (iaitu, neuron inputnya), lapisan tersebut disebut fully connected layer, atau dense layer. Input fitur yang memasuki lapisan TLU itu dianggap sebagai lapisan input neuron ( tiada pemprosesan berlaku di neuron ini). Kebiasaannya, input bias di tambah (seperti nilai b pada y=ax+b untuk linear regression model bergerak ke atas dan bawah paksi y, tetapi untuk DL ada tujuan tambahan) menggunakan neuron khas yang disebut neuron bias (Ia ditetapkan dengan nilai 1). Gambarajah di bawah menunjukkan perceptron dengan dua input, satu input bias dan tiga output. . . Apa tujuan lain bias? kenapa nilainya disetkan dengan nilai 1? . Anda tahu bahawa nilai output untuk 1 neuron TLU dan 1 input ditentukan oleh input, weight dan activation function step heaviside seperti berikut, . y = f (x₀ × w₀) . Sekiranya input adalah x₀ = 0 maka y = f (0) = 1. . Ini menyebabkan neutron tersebut sentiasa menghasilkan output yang sama (1) walaupun nilai weight w₀ berubah-ubah. Ia menyebabkan neuron itu berhenti belajar (neuron tidak aktif). Nilai bias=1 (y = f (x₀ × w₀ + 1) ), memastikan supaya neuron itu masih aktif walaupun nilai inputnya 0 (bias mengubah takat treshold atau trigger value activation function untuk neuron tersebut). . Semestinya nilai bias=1 sahaja ker? Tidak! . Bias juga adalah learnable parameter seperti weight parameter. Nilai 1 itu adalah tetapan permulaannya sahaja. Merujuk kepada gambarajah perceptron di atas, rumus untuk menghitung output lapisan fully connected adalah seperti berikut. . Penerangan rumus: . X mewakili matrix fitur input. Ia mempunyai satu row pada setiap rekod (juga di panggil sample atau instance) dan satu column pada setiap fitur (Awak bayangkan row dan column pada MS Excel). Merujuk pada gambarajah perceptron di atas, jika kita ada 1000 instance, maka saiz matrik X adalah (1000, 2). | Matrix weight W mengandungi semua sambungan weight antara neuron input dan neuron output kecuali neuron bias. Ia mempunyai satu row bagi setiap neuron input dan satu column bagi setiap neuron TLU lapisan output. Merujuk pada gambarajah di atas (kita ada 2 neuron input dan 3 neuron output), maka saiz matrix W adalah (2,3). | Vektor bias b mengandungi semua hubungan weight antara neuron bias dan neuron ouput. Iaitu ia mempunyai satu neuron bias bagi setiap neuron output TLU. | Fungsi φ ialah fungsi activation. TLU menggunakan fungsi step sebagai fungsi activationnya (kita akan membincangkan fungsi activation lain pada artikel yang seterusnya). | . Bagaimanakah proses training dilakukan oleh perceptron? . Konsepnya adalah sama dengan yang telah saya jelaskan pada artikel yang sebelum ini. Seperti contoh, setiap data instance atau sample itu dilabelkan dengan nilai target seperti contoh, Hujan(1) &amp; Tidak(0), Dalam proses training, hanya satu instance atau sample di sumbat masuk pada satu masa. Namun hanya input fitur x (tanpa nilai target) sahaja yang akan disambungkan pada neuron TLU. Manakala nilai target daripada instance itu akan digunakan untuk mengukur error (nilai ramalan - target label). Output TLU neuron menghasilkan (melalui fungsi step) nilai ramalan sama ada 1 atau 0 berdasarkan pada variasi nilai weight w. Pada setiap kali (melalui proses iteration) neuron output itu menghasilkan ramalan yang salah, ia akan mempertingkatkan nilai weight w antara neuron input dan TLU tersebut sehingga ramalannya menjadi betul. Iaitu pada setiap iteration, nilai weight w akan diupdatekan (lihat rumus di bawah. i adalah row, j adalah column) mengikut error sama ada ke arah 1 atau 0. Tetapi macam mana nak dikaitkan nilai dengan nilai error (ramalan - target label)? . Secara logiknya adalah dengan mengurangkan weight w jika neuron diaktifkan (1) walaupun ia sepatutnya tidak (0) diaktifkan, (ramalan: y = 1 dan target: t = 0). . Sebaliknya dengan meningkatkan weight w jika neuron tidak (0) diaktifkan walaupun seharusnya diaktifkan (1), (ramalan: y = 0 dan target: t = 1). . Oleh itu kita boleh gantikan dengan . Iaitu, jika sepatutnya aktif (1): . Δw(i,j)=-(0–1)=1 (tingkatkan weight w) . dan jika tidak sepatutnya aktif (0): . Δw(i,j)=-(1–0)=-1 (kurangkan weight w) . Kita masih lagi ada satu masalah, bagaimana kalau nilai input X adalah negative? Ini akan menyebabkan nilai output neuron menjadi terbalik . output TLU = h(-XW + b) . Keadaan ini akan menyebabkan neuron tidak diaktifkan walaupun sepatutnya ia perlu diaktifkan (t=1, y=0). Begitu juga sebaliknya (t=0, y=1). Oleh itu rumus ini diperbaiki menjadi seperti berikut, . di mana: . w(i,j) adalah weight yang menghubungkan input i ke output neuron j | y(j) adalah output ramalan | t(j) adalah nilai target label | x(i) adalah input fitur | µ adalah kadar kelajuan pembelajaran (learning rate). | . Apa keperluannya untuk set nilai learning rate? Tujuannya adalah untuk memperlahankan sedikit kadar kelajuan neuron itu belajar. . Aiik! kenapa nak diperlahankan pulak? Bukan lagi cepat lagi bagus ker? Tidak! . Macam ni lah. Ia ibarat macam anda nak memasukkan benang ke dalam lubang di jarum. Cucuk masuk cepat-cepat bagus ke? Masih ingat di artikel sebelum ni? Learning rate juga adalah salah satu hyperparameter tuning yang anda perlu lakukan. . Di bawah adalah contoh mudah penggunaan perceptron. Anda perlulah mempunyai ilmu asas dalam programming untuk memahami kod python itu. . Sebelum itu. Mungkin ada yang tak pasti macam mana nak setup environment untuk menjalankan aktiviti ini? Ikut langkah di bawah . Pastikan anda ada account google (gmail, gdrive) | Login ke Google Colab | Klik New Notebook | Copy-paste kod di bawah | Klik kod pada cell notebook | Klik simbol start di bahagian atas kiri cell | Sila lihat screenshot seperti di bawah. . . Apa yang anda perlu buat dengan kod ini? Anda cuma perlu tekan butang run sahaja. Kemudian cubalah baca komen-komen di &quot;#&quot;, yang telah saya coretkan pada kod tersebut untuk memahami fungsinya. Cuba main-main dengan kod itu. Jangan takut, tukarlah apa-apa sahaja yang tercetus di hati anda. . &quot;Belajar melalui pengalaman, Belajar melalui kesilapan&quot; . . import numpy as np # 1. Kita guna IRIS data download daripada sklearn library # Apa itu IRIS Data:-&gt; https://en.wikipedia.org/wiki/Iris_flower_data_set # 2. Kita guna Perceptron daripada library sklearn (kita tak guna KERAS Tensorflow atau Pytorch buat masa ini) from sklearn.datasets import load_iris from sklearn.linear_model import Perceptron # 3. Kita guna jer function load_iris untuk download IRIS data ke variable iris iris = load_iris() # 4. Uncomment ni kalau nak paparkan iris data. Iris data ada 4 input fitur #print(iris.data) # 5. Uncomment ni kalau nak paparkan iris target label. Iris data ada 3 target label klas (0,1,2) # 0-&gt;Setosa, 1-&gt;Versicolor, 2-&gt;Virginica : (perceptron hanya boleh klasifikasi 2 klas sahaja) #print(iris.target) # 6. Untuk contoh ini, kita cuma guna 2 input fitur sahaja daripada iris data # &quot;:&quot; bermaksud ambil semua row, (2,3) bermaksud ambil fitur column element ke 3 dan 4 sahaja (ingat array index bermula dari 0) # Iaitu fitur: 3-&gt;petal length, 4-&gt;petal width X = iris.data[:, (2, 3)] # Tukarkan klas 0-&gt;1, 1 dan 2-&gt;0 (Tukar kepada Klas Binary (1,0) untuk kegunaan Perceptron) # 1-&gt;Setosa atau 0-&gt;Bukan Setosa y = (iris.target == 0).astype(np.int) # Iris setosa? #7. Uncomment untuk lihat hasil penukaran data #print(X) #print(y) #Cipta Perceptron Neuron per_clf = Perceptron() #Train Model Perceptron dengan Data input X dan Data Target Label y per_clf.fit(X, y) #Gunakan model untuk membuat ramalan klasifikasi menggunakan Test Data [5.1,1.8] y_pred = per_clf.predict([[5.1, 1.8]]) #Paparkan Hasil Prediksi (1-&gt;Setosa atau 0-&gt;Bukan Setosa) print(y_pred) . [0] . Ok. Saya rasa kita berhenti di sini dahulu. Untuk artikel seterusnya, saya akan cuba untuk mengimplementasikan satu contoh lengkap penggunaan perceptron bagi tujuan klasifikasi binari. . Assalamualaikum dan InsyAllah kita bertemu lagi. .",
            "url": "https://megatazm.github.io/MyDLBlog/deep%20learning/2020/12/29/basic-dl.html",
            "relUrl": "/deep%20learning/2020/12/29/basic-dl.html",
            "date": " • Dec 29, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Pengenalan Kepada AI, ML & DL",
            "content": "Salam semua. Kita selalu mendengar perkataan “Artificial Intelligent” atau “AI”. Kalau masa awal-awal dulu kita rasa kembang hidung bila dapat mengguna perkataan ini dalam perbualan atau pun ceramah kita. Tapi, adakah setakat tahu menyebutnya sahaja sudah cukup? Tidak kah teringin untuk mengetahuinya dengan lebih mendalam? Ya, saya mahu! Anda bagaimana? Mari kita lakukan sedikit kajian. Maklumat di hujung jari anda! . Selain daripada AI, mungkin juga anda pernah dengar terma Machine Learning (ML) atau Deep Learning (DL) kan. Sejak kebelakangan ini kerap sangat kita dengar tiga perkataan ini sinonim dengan terma Data Science lah Data Analytic lah kan? Di sini saya nak bincangkan berkenaan tiga terma yang popular ini. Apa bendanya AI, ML, dan DL ni? Ahh zaman sekarang ni apa pun google jer. . . Ohh! DL adalah subset ML dan subset AI. AI dalam bahasa melayunya “kecerdasan buatan” boleh dicapai melalui pelbagai teknik. ML adalah salah satu tekniknya yang popular di masa kini. Manakala DL adalah salah satu teknik algoritma ML yang sedang hangat diperkatakan. Selain DL ada banyak lagi algoritma-algoritma lain yang popular seperti SVM, XGBoost, Random Forest yang sangat bagus untuk data yang tersusun dalam bentuk tabular data atau pun database. DL pula sangat berkuasa untuk menyelesaikan isu berkaitan “perceptual problem” seperti data yang berkaitan dengan imej, video, suara, dan bahasa. . Secara teorinya semakin banyak input data yang berkualiti dibekalkan, semakin baik prestasi outputnya. Namun, Gambarajah di bawah menunjukkan, prestasi algoritma tradisional seperti SVM, Random Forest, XGBoost akan mencapai takat tepu mendatar walaupun bekalan data yang di sumbat masuk semakin banyak. Sebaliknya, prestasi NN pula di lihat boleh ditingkatkan sejajar dengan jumlah input data yang semakin banyak. . . Ehh sekejap, ini algoritma NN (Neural Network), bukan DL (Deep Learning)! . Pada yang tidak tahu, DL ini adalah nama branding terkini untuk NN yang di pelopori oleh Bapa Deep Learning, Geoffry Hinton. Apa tu Neural Network? mungkin anda tertanya-tanya kan. Takpa itu letak di tepi dulu, cuba lihat gambarajah di bawah. . . Gambarajah architecture NN ini terdiri daripada 3 lapisan, iaitu:- . Lapisan Pertama, Input Layer beserta 3 node atau feature | Lapisan Kedua, Hidden Layer beserta 4 node atau feature | Lapisan Ketiga, 1 Output node. | . Ini merupakan contoh architecture asas NN yang sekarangnya dipanggil Shallow NN. Pada masa dahulu lebih kurang pada tahun 1950 - 1960, architecture Shallow NN sahaja lah yang mampu di capai, namun kemudiannya idea NN ini terkubur berdekad-dekad lamanya (kita akan bincangkan sejarah DL kemudian). Kini, architecture NN boleh di bina dengan lebih Deep, jumlah node dan lapisan yang lebih banyak dan kompleks. Secara teorinya semakin banyak node dan lapisan architecturenya maka semakin tinggi lah kerumitan masalah yang ia boleh selesaikan, tetapi semakin tinggi pula kuasa pemprosesan yang diperlukan. . Ok. Sebelum kita menjebakkan diri ke dalam dunia DL, kenali ML terlebih dahulu. . Machine Learning . Machine learning jika diterjemahkan secara terus kepada bahasa melayu apa maksudnya? Mesin Belajar? Belajar Mesin? atau mungkin lebih tepat jika ia bermaksud mesin yang boleh di ajar. Mesin yang satu hari nanti boleh mengajar &quot;diri&quot;nya sendiri mungkin kedengaran menakutkan ataupun kelakar, tetapi menurut Elon Musk, jika penggunaan teknologi DL ini tidak di kawal-selia dengan baik ia mungkin bakal menjadi lebih bahaya daripada kepala bom nuklear! . Ok, kenapa ML adalah teknik AI yang sangat hebat di waktu ini. . Sebagai contoh, katakan kita nak mengajar komputer untuk mengenali haiwan yang dikenali oleh manusia sebagai kucing. Mungkin agak mudah mengajar bayi yang berumur 3 tahun untuk mengenalinya, tetapi bolehkah anda bayangkan bagaimana sukar untuk melakukannya melalui teknik traditional AI? Secara traditionalnya, untuk memberi arahan atau mengajar komputer membuat perbandingan, ia boleh dilaksanakan dengan pendekatan rule-based melalui programming ataupun pengaturcaraan. Seperti contoh, dengan berpandukan pada pixel-pixel gambar seekor kucing seperti di bawah, anda perlu memprogram ribuan kod rule-based yang kompleks untuk membolehkan komputer mengenali kucing tersebut. . . Bisa lakukannya? Ya mungkin boleh, berkat ketekunan dan kesabaran anda. Alhamdulillah selesai masalah. . Tunggu! Tunggu sebentar! Masih awal untuk bergumbira. . Cuba lihat gambar-gambar kucing di bawah. Bagaimana pula dengan kucing-kucing lain? ada ratus ribuan kucing di luar sana malahan berpuluh-puluh spesis kucing wujud di dunia ini. Bagaimana pula dengan keadaan kucing-kucing itu? ada yang sedang mengendap di tepi bakul, di urut tengkoknya, mulut mengiau luas, mendukung anaknya, dan sebagainya. . . Dengan kata lain, bagaimana kita nak &quot;generalize&quot; kan kod rule-based ini supaya ia dapat mengenali kucing-kucing yang belum di &quot;lihat&quot; oleh komputer. Disinilah kekuatan ML mengatasi teknik traditional AI. Lihat gambarajah di bawah. Kaedah traditional programming, seperti yang dinyatakan di atas, ia memerlukan manusia membina program berdasarkan pada input data untuk menghasilkan model klasifikasi rule-based. Manakala, ML tidak memerlukan manusia untuk membina program tersebut secara eksplisit. Apa yang ML perlu ialah bantuan manusia melabelkan jawapan betul pada setiap input data, dan menyalurkankannya ke dalam komputer. Seterusnya, algoritma ML memproses data tersebut lalu membina model yang boleh mengklasifikasi data input yang belum di &quot;lihat&quot; sebagai kucing atau bukan kucing. Oleh kerana model klasifikasi tersebut boleh di bina secara automatik dan pantas oleh algoritma ML (dengan sedikit bantuan daripada manusia), kita boleh meningkatkan prestasi &quot;generalization&quot; model tersebut dengan menyumbat masuk pelbagai jenis gambar kucing kepada algoritma ML itu dengan skala yang besar (lebih banyak input data yang pelbagai, lebih tinggi prestasi generalization sebuah model). . . Secara informalnya, ML boleh didefinasikan sebagai:- . Teknik AI yang membolehkan machine berupaya belajar tanpa perlu di program secara eksplisit Secara formalnya pula ia didefinasikan sebagai:- . Suatu program komputer dikatakan belajar dari pengalaman E terhadap suatu kelas tugasan T dengan prestasinya di ukur dengan P. Prestasi pada ukuran P terhadap tugasan T meningkat melalui penambahan pengalaman E. Definasi E, T &amp; P dengan frasa lebih mudah:- . T = Tugasan untuk mengenali kucing di dalam gambar | E = Pengalaman melihat banyak gambar-gambar kucing | P = Kebarangkalian program mengenal pasti kucing di dalam gambar | . Untuk pengetahuan anda, ML terdiri dari beberapa kategori; iaitu Supervised Learning, Unsupervised Learning, Semi-Supervised Learning, Self-Supervised Learning, Reinforcement Learning, dan banyak lagi. Cuma kali ini, kita fokus pada teknik yang saya bincangkan di atas iaitu, Supervised Learning. Supervised Learning sangat mustajab digunakan untuk menyelesaikan masalah berkaitan Classification dan Regression (Saya akan jelaskan hal berkenaan regression kemudian). . Secara analoginya, Supervised Learning Classification adalah ibarat mengajar kanak-kanak mengenal kucing menggunakan kad flip. . Cikgu: Ini apa? | Murid: Itu ayam. | Cikgu: Bukan, Ini kucing. | Murid: Itu kucing. | . Supervised Learning . Seperti yang dinyatakan sebelum ini, idea supervised learning classification adalah berdasarkan pada konsep mengajar kanak-kanak (murid) menggunakan kad flip. . Cikgu = Supervisor | Murid = Komputer | Input Data = Gambar Kucing | Input Label = Kapsyen pada Kad Flip | . Gambarajah di bawah menunjukkan aliran proses supervised learning. . . Langkah pertama untuk menjalankan proses Supervised Learning (SL) adalah mengumpul dan melabel atau menganotasi data. Kita bernasib baik sebab gambar-gambar kucing sudah pun ada banyak di google.com, mudah lah untuk kita mencuba ML dan DL nanti. Kita bukan sahaja boleh mendapatkan data daripada google.com dan Google Dataset Search, ada banyak benchmark data yang telah digunakan oleh penyelidik-penyelidik, ada di internet. Senarai dataset tersebut boleh di perolehi di sini, TowardsAI dan Wikipedia. . Ini adalah suatu kemudahan kan? banyak data sudah sedia ada untuk memberi galakan kepada anda menerokai teknologi ini (Anda masih perlu melakukan sedikit proses penyesuaian data, ianya agak mudah dilakukan). . Data Preprocessing . Namun, jika anda ingin mengunakan ML untuk menyelesaikan permasalahan sebenar di luar sana, pengumpulan dan penyediaan datanya tidak lah semudah itu. Anda perlu melalui proses Data Pre-processing terlebih dahulu. . Data Cleaning Missing Data Contohnya, jika ada atribut rekod di dalam data tersebut hilang, padamkan rekod itu. | Ataupun simpan rekod itu, tetapi nilai pada atribut yang hilang digantikan dengan nilai average atribut. (Rekod dan atribut adalah satu jaluran informasi dalam data) | . | Jika data tersebut adalah imej, kita boleh membuang data yang tidak sesuai secara visual sebelum atau secara automatik selepas training. Fastai adalah framework deep learning untuk Pytorch, mempunyai fitur untuk menyenaraikan data yang tidak baik secara automatik selepas menjalankan proses training. | Noisy Data Noisy data adalah data yang dikatakan &quot;meaningless&quot;, &quot;takda maknanya&quot;. Macam bunyi noise + muzik, bunyi noise itu kalau tak ada lagi sedap bunyi muziknya. Ia boleh diuruskan melalui teknik seperti Binning, Regression, dan Clustering (melandaikan data, mengurangkan zig-zag). Ada juga yang mencadangkan dengan menambahkan lebih banyak data yang berkualiti untuk mengurangkan kesan noisy data. Kaedah-kaedah lain adalah seperti teknik dimension reduction (seperti algoritma PCA), teknik Regularization, dan Cross Validation. Ironinya noise (random noise) merupakan rakan baik untuk algoritma DL. Contohnya, random noise sengaja di suntik masuk ke dalam data (teknik Data Augmentation) sebelum ia disalurkan ke dalam algoritma DL regression untuk meningkatkan tahap generalization modelnya (salah satu teknik Regularization dalam DL). Manakala algoritma DL Generative Adversarial Network (GAN) pula menggunakan random noise sebagai dasar untuk mencipta &quot;fake face images&quot;, muka manusia tiruan. | . | Outlier Data Outlier data adalah data yang berada jauh daripada kelompok data lain dari segi kesamaan dan keberkaitannya. Kebiasaannya outlier data perlu di buang (mungkin disebabkan human error), namun ada ketikanya seperti untuk anomaly detection (mengesan sesuatu di luar kebiasaan seperti aktiviti hacker, network intrusion, dan penipuan dalam talian), dalam konteks ini outlier data adalah penting. | . | . | Data Transformation Normalization Normalization menyeragamkan skala nilai pada setiap atribut di rekod. Kebanyakkan algoritma memerlukan semua atribut tersebut diseragamkan di antara julat yang sama. Contohnya, jika julat atribut Harga Rumah adalah 50,000 dan 500,000 dan julat atribut Jumlah Bilik adalah 2 dan 8 (Contoh atribut data berkenaan hartanah), ia perlu diseragamkan di dalam julat yang sama untuk membolehkan algoritma berfungsi dengan baik. Algoritma seperti NN sebagai contoh, memerlukan input data yang diseragamkan kepada nilai di antara 0 dan 1. | . | Discretization Menukarkan julat nombor tertentu kepada perkataan. Contohnya, nilai antara 1 dan 17 -&gt; Kanak-Kanak, 18 dan 39 -&gt; Dewasa, 40 dan 59 -&gt; Pertengahan, 60 dan ke atas -&gt; Wargamas. | . | Encoding Categorical Value mengekod nilai atribut dari perkataan kepada nombor binary. Contoh, Kucing -&gt; 100, Ayam -&gt; 010, dan Monyet -&gt; 001. Ini perlu dilakukan terutamanya untuk algoritma seperti NN yang hanya boleh berfungsi dengan nilai input, outputnya di dalam bentuk nombor sahaja. | . | Data Labeling Data labeling atau annotation yang diperkatakan di atas juga adalah teknik data preprocessing yang mesti dilakukan sebelum proses supervised learning. Jika data tersebut adalah imej, anda perlu menanda pada imej tersebut, objek yang ingin diklasifikasikan. Bayangkan jika anda perlu menganotasikan pada 50 ribu keping gambar yang mana setiap keping gambar itu ada 1000 orang! | . | . | Data Dimension Reduction Feature Extraction Memilih atribut-atribut yang relevan dan menggabungkannya menjadi satu atribut yang baharu. | . | Feature Selection Memilih atribut yang relevan dan membuang atribut yang tidak relevan. | . | Kedua-dua teknik ini bukan sahaja mengurangkan dimensi data, ia juga dikatakan akan menjadikan data tersebut lebih bermakna dan mudah di latih oleh algoritma ML. Ada banyak algoritma yang boleh digunakan untuk data dimension reduction ini, tapi saya tak membincangkannya di sini kerana algoritma DL yang kita akan terokai nanti dikatakan mampu beraksi dengan baik tanpa perlu melalui proses ini dilakukan secara manual. | . | . Model Training . Apakah yang dimaksudkan dengan model training? . Graf di bawah menunjukkan hubungan antara dua pemboleh ubah X, Y dan garisan persamaan linear di garis melintasi data yang diplotkan. Proses ini dikenali sebagai Simple Linear Regression Model, contoh ini adalah yang paling mudah kita gunakan kerana ia hanya melibatkan dua pemboleh ubah (atribut 2 dimensi). Bulatan kuning adalah training data manakala garisan biru adalah model yang digariskan oleh algoritma ML melalui proses training. Anak panah berwarna merah merupakan jarak atau error antara training data dan nilai pada garisan model f(X)-&gt;Y. Melalui proses training, algoritma ML perlu membina garisan model f(X)-&gt;Y yang minima jumlah errornya berbanding dengan point training data (seperti yang ditunjukkan pada graf sebelah kanan). . . Rumus di bawah adalah persamaan linear yang merujuk pada garisan yang berwarna biru. Nilai pemboleh ubah a menentukan kecerunan, manakala pemboleh ubah b menentukan ketinggian garisan tersebut pada paksi Y. Graf di sebelah kiri merupakan garisan permulaan model linear regression itu pada ketika a=0 dan b=1. Pada ketika ini nilai prediksi model f(X) -&gt; Y pada setiap titik x training data adalah 1. Jumlah error ketika ini boleh di hitung dengan menggunakan rumus Mean Square Error (MSE). . . Merujuk pada rumus MSE di atas: . x adalah independant variable ataupun input fitur yang digunakan oleh model untuk melakukan prediksi nilai dependant variable ataupun target value, y. | prediction(x) adalah nilai prediksi y di input x berdasarkan model linear regression ketika di suatu nilai a dan b. | D adalah training data yang telah dilabelkan. x ialah input fitur manakala y ialah output labelnya. Contoh graf di atas menunjukkan ada 6 data point dengan input fitur dan label seperti berikut:- (x1,y1), (x2,y2), (x3,y3), (x4,y4), (x5,y5), (x6,y6) . | N adalah jumlah training data (contoh di atas, N = 6). | . Untuk menghitung MSE, pada setiap data point, dapatkan error antara nilai y label dan y prediksi, kemudian kuasa duakannya. Lakukan ini pada setiap data point, kemudian jumlahkan kesemuanya. Akhir sekali, bahagikan hasil jumlah tersebut dengan jumlah training data, N (merujuk pada contoh di atas, N = 6). . Proses yang merujuk pada graf di kiri itu adalah dikatakan sebagai &quot;initial iteration per 1 epoch&quot;. . Apa maksudnya? . Initial di sini bermaksud nilai permulaan parameter a dan b bagi mengariskan kedudukan awal garisan model linear tersebut. Nilai a dan b itu boleh ditentukan supaya bermula dengan nilai kosong ataupun nilai random (Untuk architecture NN yang kompleks kita mungkin perlu menggunakan kaedah lain yang lebih spesifik). . Iteration adalah frekuensi algoritma ML itu disuapi sebahagian daripada training data. Epoch pula adalah frequency kesemua training data itu selesai di proses oleh algoritma ML tersebut. . Boleh faham tak maksudnya? Ok, saya jelaskan dengan lebih terperinci. . Dalam keadaan sebenar, kesemua training data itu tidak di suap masuk ke dalam algoritma secara serentak. Ia di suap mengikut kumpulan atau batch. Contoh, jika jumlah training data adalah 2000 (1 epoch = 2000 data di proses). Jika anda setkan saiz batch = 100, maka setiap 1 epoch = 20 iteration (20 x 100 = 2000). Jika anda setkan training proses sebanyak 250 epoch maka total iterationnya adalah 20 x 250 = 5000. Ingat, pengiraan MSE berlaku pada setiap iteration. Macam mana, Ok? . Untuk contoh di atas, oleh kerana training datanya cuma ada 6 sahaja, maka setiap 1 epoch ada 1 iteration sahaja (kita setkan saiz batch = jumlah training data, iaitu 6). Oleh itu pada setiap 1 iteration, nilai MSE di hitung berdasarkan pada kedudukan terkini garisan linear model. Kedudukan garisan linear model akan berubah pada setiap iteration. Dengan harapan nilai MSEnya semakin kecil. . Apa yang akan berlaku jika anda setkan training proses sebanyak 250 epoch? Cukup ker? . Maksudnya, algoritma ML tersebut ada masa sebanyak 250 iteration untuk mengariskan linear regression modelnya (melalui kombinasi nilai parameter a dan b) supaya MSE mencapai nilai seminima yang mungkin. Secara teorinya, lagi lama iteration maka semakin tinggilah peluangnya mencapai nilai MSE yang paling minima. Namun ini bergantung kepada keupayaan algoritma ML menentukan nilai parameter a dan b yang optimum dalam jangkamasa yang singkat. Bayangkan jika algoritma ini menggunakan teknik random atau brute-force bagi menentukan nilai parameter a dan b itu. Iteration sebanyak 250 mungkin tidak mencukupi kan? . Algoritma Deep Learning menggunakan teknik optimization yang di panggil &quot;Gradient Decent&quot; untuk mencapai nilai MSE yang minima, jauh lebih pantas berbanding teknik secara random. . Bayangkan jikalau bukan 2, tapi ada beribu parameter yang perlu ditentukan? Dengan Gradient Decent, ia mungkin memakan masa dalam beberapa puluh minit, tapi jika secara random, anda mungkin perlu menunggunya selama beribu-ribu tahun! . . Gambarajah di atas adalah contoh linear regression model yang mencapai tahap optimum pada iteration yang ke-28 berdasarkan pada jumlah training datanya. . Model Validation . Saya harap anda sudah memperolehi kefahaman asas berkenaan model training, tapi mungkin ada yang tertanya-tanya, apa kaitannya validation data dengan model training? Saya pun langsung tak melibatkan validation data di dalam penerangan berkenaan model training tadi. . Jika anda merujuk kembali pada gambarajah aliran proses supervised learning. Ada tiga jenis data yang perlu disediakan selepas proses labeling data, . Training Data | Validation Data | Testing Data | . Seperti yang telah saya jelaskan sebelum ini, training data diperlukan untuk membina model classification ataupun regression. Manakala, testing data pula adalah &quot;unseen data&quot; yang telah diasingkan bagi tujuan mengukur prestasi model tersebut. . Sebenarnya fungsi validation data juga adalah sama dengan test data iaitu mengukur prestasi model yang telah di bina. Cuma bezanya adalah, validation data digunakan untuk mengukur prestasi model ketika di dalam proses model training. . Ada beberapa teknik validation iaitu, . Holdout Method Sebahagian dari training data diasingkan kepada validation data (mungkin dalam nisbah 90% training dan 10% validation data, atau 80% dan 20%). | . | K-Fold Cross Validation . Teknik ini sesuai digunakan untuk membolehkan anda mengoptimumkan penggunaan training data. Terutamanya, jika anda tidak mempunyai training data yang cukup banyak. . | Gambarajah di bawah menunjukkan gambaran proses 10-fold cross validation (K=10). . | Berikut adalah langkah-langkah proses 10-fold cross-validation, . Asingkan data kepada 10 bahagian yang sama atau &quot;folds&quot;. | Train model anda menggunakan 9 folds data yang pertama. | Buat penilaian prestasi model itu menggunakan baki ataupun &quot;hold-out&quot; data fold yang ke-10 tadi. | Ulangi langkah (2) dan (3) sebanyak 10 kali, di mana setiap ulangan menggunakan hold-out data fold yang berbeza. | Hitungkan purata prestasi model daripada kesemua 10 hold-out data folds tersebut. | | . | Stratified K-Fold Cross Validation . Teknik ini masih menggunakan langkah yang sama seperti di atas. Stratified adalah nama teknik sampling data yang digunakan untuk memilih data ketika mengasingkan data kepada training dan validation. Teknik sampling data yang digunakan oleh dua teknik validation sebelum ini adalah random data sampling. Teknik stratified data sampling digunakan jika data yang anda perolehi itu tidak seimbang. Contohnya, training data untuk harga rumah yang mahal lebih banyak daripada harga rumah yang murah, ataupun training data gambar kucing ada lebih banyak daripada gambar anjing dan monyet. | . | . K-fold cross validation dikatakan, . Secara signifikan mengurangkan &quot;bias&quot; kerana menggunakan sebahagian besar training data yang ada. Ia juga secara signifikannya mengurangi &quot;variance&quot; kerana sebahagian besar data juga digunakan sebagai validation data. . Bias? Variance? mungkin ada yang tertanya-tanya akan maksudnya. . Istilah Bias &amp; Variance ini berkait rapat dengan keperluan untuk mengukur prestasi model ketika dalam proses model training yang kemudiannya dijadikan sebagai rujukan bagi melakukan proses Model Tuning. . Model Tuning &amp; Testing . Berkenaan dengan model tuning, berikut adalah beberapa istilah penting yang perlu anda fahami. . Bias &amp; Variance | Underfitting &amp; Overfitting | Generalization | Hyperparameter Tuning, Regularization &amp; Optimization . | Wow! Banyaknya nak kena hafal. . Jangan risau, tak banyak mana pun sebenarnya, sebab mereka ni semua saling berkaitan. Yang penting kita jelas dengan maksudnya supaya tak terkeliru dan dikelirukan. Ini kerana, di luar sana ada ramai yang mengamalkan teknik ini, . &quot;If you can&#39;t convince them, confused them&quot; . Untuk memudahkan anda faham, gambarajah di bawah menggarap maksud istilah Bias &amp; Variance, Underfitting &amp; Overfitting, dan Generalization sekali gus. . . Gambarajah di atas menunjukkan error rate menurun apabila kompleksiti model meningkat (Peningkatan kompleksiti model adalah berkadar terus dengan frequency iteration atau epoch). Iaitu, lagi lama proses model training berjalan maka lagi kompleks lah model yang terhasil. Secara teorinya, semakin lama model di train maka semakin kecil lah errornya (menghampiri kosong), namun ini tidak semestinya baik. . Kenapa pulak? Error model dah zero, mesti lah terbaik kan? Tidak! . Cuba anda lihat tiga graf kecil di bawah gambarajah itu. . Overfitting = High Variance, Underfitting = High Bias, Good Balance = Low Bias, Low Variance. . Apabila training iteration tak mencukupi, model yang dihasilkan adalah simple iaitu garisan linear yang tidak mampu untuk &quot;fit&quot; pada trend data yang non-linear. Sebaliknya, jika terlalu lama di train, model yang terlampau &quot;fit&quot; pada trend data itu akan terhasil. Cuba anda perhatikan, apabila semua garisan model itu &quot;overfit&quot; kerana ia melalui kesemua titik training data. Oleh itu, errornya memanglah menjadi kosong kan? (masih ingat pengiraan MSE?). Namun, prestasi model ini hanya baik pada data yang pernah dilihatnya sahaja dan bukan pada &quot;unseen&quot; data. . Inilah yang dikatakan sebagai &quot;Bias &amp; Variance Tradeoff&quot;. Iaitu, mencari Good Balance, Sweet Spot ataupun Generalized Model, mampu memberi prestasi yang baik apabila modelnya di nilai dengan data baharu. Oleh itu, dengan berpandukan pada titik error rate terendah validation dan test error, maka anda boleh menentukan nilai iteration atau epoch yang paling optimum. . Ok. Sekarang baru lah saya boleh bercakap tentang Model Tuning &amp; Testing. . Jika sudah selesai melakukan model training dengan tetapan nilai epoch yang optimum, maka anda telah bersedia untuk mengukur prestasi model anda dengan unseen test data (anda boleh melakukannya pada beberapa model terpilih). Jika anda bernasib baik, nilai ketepatannya mungkin lebih baik daripada validation error, atau mungkin sebaliknya. . Jangan cepat berpuas hati! Masih ada ruang untuk &quot;tune up&quot; prestasi model anda melalui Hyperparameter Tuning, Regularization &amp; Optimization (dalam konteks deep learning). . Hyperparameter adalah parameter pada algoritma yang boleh di ubah-ubah settingnya untuk mencari kombinasi yang optimum. Ibarat macam amplifier audio, kita pusing-pusing tombol-tombolnya untuk mencari bunyi yang paling enak. Hyperparameter juga dikatakan sebagai &quot;non-learnable&quot; parameter manakala &quot;learnable&quot; parameter hanyalah pada model parameter. Contoh model parameter ialah nilai parameter a dan b untuk simple linear regression model y = Ax + b. Ini adalah kerana nilai a dan b itu ditentukan (learned) oleh algoritma dan training data ketika proses model training. Regularization adalah teknik atau setting yang boleh meningkatkan tahap generalization model. Optimization adalah pemilihan jenis algoritma Gradient Decent (GD) dan setting parameternya. . Senarai hyperparameter pada DL algoritma adalah seperti berikut:- . Jumlah NN Hidden Layer (NN Parameter) | Jumlah Nod di setiap NN layer (NN Parameter) | Pemilihan Activation Function di setiap NN layer seperti RELU, Tanh, Sigmoid, etc (NN parameter) | Batch Normalization (Regularization) | Setting Learning Rate (GD Optimization) | Early stopping (Regularization) | L2 &amp; L1 norm (Regularizatioan) | Tambah training data (Regularization) | NN node Drop-out (Regularization) | Data Augmentation (Regularization) | Mini-batch size (GD Optimization) | Momentum (GD Optimization) | RMSprop (GD Optimization) | ADAM (GD Optimization) | Learning Rate Decay (GD Optimization) | . Banyak kan? Sebenarnya ada banyak lagi! 눈_눈 . Ini kalau nak diceritakan teori dan matematik merujuk pada semua di atas ni, Mau pecah la kepala otak saya. Tapi jangan risau, kita guna jer kod implementasinya di library Tensorflow/Keras dan Pytorch. Tapi kalau nak tune semua ni satu persatu, penat laa! lecehnya!. Ya betul memang leceh, tapi nasib baik ada library automation untuk tujuan hyperparameter tuning ni. Antara yang popular untuk Tensorflow/Keras dan Pytorch ialah, . AutoML | Keras Tuner | T-PoT | Hyperas | Talos | Hypersearch | Optuna | Determined | Ray Tune | . Banyak kan? Sebenarnya ada banyak lagi! 눈_눈 . Saya rasa cukuplah sampai di sini. Di artikel yang seterusnya InsyaAllah saya akan cuba menulis yang lebih spesifik pada teori berkaitan deep learning dan implementasinya pula. . Dengan ini, harapan saya semoga artikel ini dapat memberi manafaat kepada pembaca yang berminat meneroka di dalam teknologi ini. Jika anda ingin mengetahui dengan lebih lanjut, memanglah ada berlambak-lambak bahan-bahan pembelajaran berkenaan DL di google.com dan youtube. Tapi hampir kesemuanya adalah dalam bahasa inggeris lah, dan adalah juga sedikit dalam bahasa Indonesia. Mungkin tak menjadi masalah sangat pada rata-rata orang kita, kerana ramai orang Malaysia mahir berbahasa inggeris, pokoknya adalah minat dan kesabaran yang mendalam. . Assalamualaikum! .",
            "url": "https://megatazm.github.io/MyDLBlog/deep%20learning/2020/12/23/AI-ML-DL.html",
            "relUrl": "/deep%20learning/2020/12/23/AI-ML-DL.html",
            "date": " • Dec 23, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Artikel Lampau Berkaitan IoT",
            "content": "Sila klik di sini untuk pergi ke artikel yang dicoretkan sebelum ini. . Terima kasih. .",
            "url": "https://megatazm.github.io/MyDLBlog/iot/2020/12/17/previous-iot-article.html",
            "relUrl": "/iot/2020/12/17/previous-iot-article.html",
            "date": " • Dec 17, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that . . cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://megatazm.github.io/MyDLBlog/fastpages/2020/02/20/test.html",
            "relUrl": "/fastpages/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "An Example Markdown Post",
            "content": "Testing Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://megatazm.github.io/MyDLBlog/fastpages/2020/01/14/test-markdown-post.html",
            "relUrl": "/fastpages/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Saya adalah seorang pensyarah di UniKL MIIT. Bidang teknologi yang saya minati ialah Deep Learning, Cloud Computing, and IoT. Tujuan saya menulis artikel di sini adalah dengan harapan untuk memberi galakan dan pendedahan awal pada pelajar-pelajar sekolah menengah khasnya, juga pada semua pelajar-pelajar universiti yang mungkin berminat untuk menelaah bahan pembelajaran berkaitan teknologi ini di dalam Bahasa Melayu. Saya harap blog ini sedikit sebanyak dapat memberi manafaat kepada anda semua. .",
          "url": "https://megatazm.github.io/MyDLBlog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://megatazm.github.io/MyDLBlog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}